[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative and Computational Thinking",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Computational Thinking (CT)\nIn the broad sense, computational thinking (CT) is a problem-solving methodology that develops solutions for complex problems by breaking them down into individual steps. Well, are not most problems solved this way? Actually, yes. We all apply computational thinking methodology every day. As we will see in the example below, cooking a pot of soup involves computational thinking.\nIn the narrow sense, computational thinking is problem solving by expressing the solution in such a way that it can be implemented through a computer—using software and hardware. The term computational in CT derives from the fact that the methodology is based on core principles of computer science. It does not mean that all CT problems are solved through coding. It means to solve problems by thinking like a computer scientists.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#sec-intro-ct",
    "href": "intro.html#sec-intro-ct",
    "title": "1  Introduction",
    "section": "",
    "text": "Elements of CT\nWhat is that like? The five elements of computational thinking are\n\nProblem Definition\nThis should go without saying, before attempting to build a solution one should know what problem the solution solves. However, we often get things backwards, building solutions first and then looking for what problems to solve with them. The world of technology is littered with solutions looking for a problem.\n\n\n\n\n\n\nSolution looking for a problem\n\n\n\nSolutions looking for problems are commonplace. If someone is trying to sell you a new car when there is nothing wrong with your current car, they (salesman) have a solution (new car) but there is no problem (new car is not needed). So they might try to create a problem by selling you on the benefits of the new model.\nOn the other hand it is good to innovate and create new solutions even if not all problems the innovation solves are known beforehand. When Karl Benz combined in 1885 a one-cylinder internal combustion engine with a carriage (Figure 1.1), he created the first automobile, the Benz Patent-Motorwagen. He probably did not imagine the many future applications of the technology.\n\n\n\n\n\n\nFigure 1.1: Benz Patent-Motorwagen, the first automobile.\n\n\n\n\n\n\n\nDecomposition (Factoring)\nThis element of computational thinking ask to break the complex problem into smaller, manageable parts and by doing so helps to focus the solution on the aspects that matter, eliminating extraneous stuff.\nSmaller problems are easier to solve and can be managed independently. A software developer decomposes a task into several functions, for example, one that takes user input, one that sorts data, one that displays results. These functions can be developed separately and are then combined to produce the solution. Sorting can further be decomposed into subproblems, for example, the choice of data structure (list, tree, etc.), the sort algorithm (heap, quicksort, bubble, …) and so on.\nTo understand how something works we can factor it into its parts and study how the individual parts work by themselves. A better understanding of the whole results when we reassemble the components we now understand. For example, to figure out how a bicycle works, decompose it into the frame, seat, handle bars, chain, pedals, crank, derailleurs, brakes, etc.\n\n\nPattern recognition\nPattern recognition is the process of learning connections and relationships between the parts of the problem. In the bicycle example, once we understand the front and rear derailleurs, we understand how they work together in changing gears. Pattern recognition helps to simplify the problem beyond the decomposition by identifying details that are similar or different.\n\n\n\n\n\n\nCarl Friedrich Gauss\n\n\n\nCarl Friedrich Gauss (1777–1855) was one of the greatest thinkers of his time and widely considered one of the greatest mathematicians and scientists of all time. Many disciplines, from astronomy, geodesy, mathematics, statistics, and physics list Gauss as a foundational and major contributor.\nIn The Prince of Mathematics, Tent (2006) tells the story of an arithmetic assignment at the beginning of Gauss’ third school year in Brunswick, Germany. Carl was ten years old at the time. Herr Büttner, the teacher wanted to keep the kids quiet for a while and asked them to find the sum of the first 100 integers, \\[\\sum_{i=1}^{100}i\n\\] The students were to work the answer out on their slates and place them on Herr Büttner’s desk when done. Carl thought about the problem for a minute, wrote one number on his slate and placed it on the teacher’s desk. He was the first to turn in a solution and it took his classmates much longer. The slates were placed on top of the previous solutions as students finished. Many of them got the answer wrong, messing up an addition somewhere along the way. Herr Büttner, going through the slates one by one found one wrong answer after another and expected Gauss’ answer also to be wrong, since the boy had come up with it almost instantly. To his surprise–or dismay–Gauss’ slate showed no work, Carl had written on it just one number, 5,050, the correct answer.\nCarl explained\n\nWell, sir, I thought about it. I realized that those numbers were all in a row, that they were consecutive, so I figured there must be some pattern. So I added the first and the last number: 1 + 100 = 101. Then I added the second and the next to last numbers: 2 + 99 = 101. […] That meant I would find 50 pairs of numbers that always add up to 101, so the whole sum must be 50 x 101 = 5,050\n\nCarl had recognized a pattern that helped him see the connected parts of the problem: a fixed number of partial sums of the same value.\n\n\n\n\nGeneralization (Abstraction)\nOnce the problem is decomposed and the patterns are recognized, we should be able to see the relevant details of the problem and how we go about solving the problem. This is where we derive the core logic of the solution, the rules. For example, to write a computer program to solve a jigsaw puzzle, you would not want to write code specific to one particular puzzle image. You want code that can solve jigsaw puzzles in general. The specific image someone will use for the jigsaw puzzle is an irrelevant detail.\nA rectangle can be decomposed into a series of squares (Figure 1.2). Calculating the area of a rectangle as width x height is a generalization of the rule to calculate the area of a square as width-squared.\n\n\n\n\n\n\nFigure 1.2: Decomposing a 12 x 8 rectangle into six 4 x 4 squares to generalize computation of the area\n\n\n\n\n\nAlgorithm design\nThe final element of CT involves another form of thinking, algorithmic thinking. Here we define the solution as a series of steps to be executed. Algorithmic thinking does not mean the solution has to be implemented by a computer, although this is the case in the narrow sense of CT. The point of the algorithm is to arrive at a set of repeatable, step-by-step instructions, whether these are implemented by humans, machines, or a computer. Capturing the solution in an algorithm is a step toward automation.\n\nFigure 1.3 shows an algorithm to produce pumpkin soup, repeatable instructions that lay out the ingredients and how to process them in steos to transform them into soup.\n\n\n\n\n\n\nFigure 1.3: A recipe for pumpkin soup is an algorithm.\n\n\n\n\n\n\nMaking Pumpkin Soup\nLet’s apply the elements of computational thinking to the problem of making pumpkin soup.\n\nDecomposition\nDecomposition is the process of breaking down a complex problem into smaller, more manageable parts. In the case of making pumpkin soup, we can break it down into several steps:\n\nIngredients: Identify the key ingredients required for the soup.\n\nPumpkin\nOnion or Leek\nGarlic\nStock (vegetable or chicken)\nCream (optional)\nSalt, pepper, and spices (e.g., nutmeg, cinnamon)\nOlive oil or butter for sautéing\n\nPreparation: Break down the actions involved in preparing the ingredients.\n\nPeel and chop the pumpkin\nChop the onion and garlic\nPrepare spices and seasoning\n\nCooking: Identify the steps in cooking the soup.\n\nSauté the onion and garlic\nAdd the pumpkin and cook it\nAdd stock and bring to a simmer\nPuree the mixture\nAdd cream and season to taste\n\nFinal Steps: Focus on finishing touches.\n\nGarnish (optional)\nServe and taste for seasoning adjustments\n\n\n\n\nPattern recognition\nWhat are the similar elements or repeating steps in the problem?\n\nCommon cooking steps: Many soups follow a similar structure: sautéing vegetables, adding liquid, simmering, and then blending or pureeing.\nIngredient variations: While the exact ingredients for pumpkin soup may vary (e.g., adding coconut milk instead of cream), the basic framework of the recipe remains the same.\nTiming patterns: There’s a pattern to the cooking times: first sautéing for a few minutes, then simmering the soup for about 20-30 minutes, followed by blending.\n\n\n\nGeneralization\nWe can generalize (abstract) the process of making pumpkin soup into a more general recipe for making any pureed vegetable soup, regardless of the specific ingredients.\n\nEssential components:\n\nA base (onions, garlic, or other aromatics)\nA main vegetable (in this case, pumpkin)\nLiquid (stock, broth, or water)\nSeasoning and optional cream\n\nGeneral process:\n\nSauté aromatics.\nAdd the main vegetable and liquid.\nSimmer until the vegetable is tender.\nBlend until smooth.\nAdjust seasoning and add cream if desired.\n\n\n\n\nAlgorithm design\nHere is a simple algorithm for making pumpkin soup:\n\nPrepare ingredients:\n\nPeel and chop the pumpkin into cubes.\nChop the onion and garlic.\n\nSauté aromatics:\n\nIn a pot, heat oil or butter over medium heat.\nAdd chopped onion and garlic, sauté for 5 minutes until softened.\n\nCook pumpkin:\n\nAdd chopped pumpkin to the pot and sauté for 5 minutes.\nAdd stock to cover the pumpkin (about 4 cups) and bring to a boil.\n\nSimmer:\n\nLower the heat, cover, and let the soup simmer for 20-30 minutes until the pumpkin is tender.\n\nBlend the soup:\n\nUse an immersion blender or transfer the soup to a blender. Puree until smooth.\n\nAdd cream and seasoning:\n\nStir in cream (optional) and season with salt, pepper, and spices to taste (e.g., nutmeg or cinnamon).\n\nServe:\n\nPour into bowls and garnish with optional toppings (e.g., a swirl of cream, roasted seeds, or fresh herbs).\n\n\nFigure 1.3 is a specific implementation of the algorithm.\nBy applying computational thinking, we decomposed the task of making pumpkin soup into smaller steps, recognized patterns in the cooking process, abstracted the general process for making soups, and designed an algorithm to efficiently make pumpkin soup. This method helps streamline the cooking process, ensures nothing is overlooked and provides a clear, repeatable procedure.\n\n\n\nImportance of CT\nComputational thinking as a methodology is applied nowadays in almost any domain and to many problems. Decomposing a problem into parts, recognizing patterns, abstracting the problem essentials and capturing them in an algorithm is an effective approach to deal with many problems.\nThe rise of computational thinking is also due to the fact that many more problems are solved through software and computing today than in the past. We have become very good at capturing the essential details of processes and phenomena through models, which by their very nature are abstractions of the prevailing patterns in those processes. And the implementation of the models frequently involves the design and deployment of algorithms.\nFinancial analysts make investment decisions based on mathematical models of market behavior. Banks decide whether to award a loan based on statistical models for the probability of loan default. Insurance premiums are based on risk models. A healthcare provider chooses a treatment plan based on assessment of risk factors and predictions of disease progression, based on medical knowledge and models that describe patient outcomes.\nIn 2011, Mark Andreessen of VC firm Andreessen-Horowitz (known as a16z) declared\n\nSoftware is eating the world.\n\nWhy was this happening? Andreessen (2011) cites several reasons, among them\n\nSix decades into the computer revolution, four decades since the invention of the microprocessor, and two decades into the rise of the modern Internet, all of the technology required to transform industries through software finally works and can be widely delivered at global scale.\n\nThe largest book seller, Amazon, is a software company. Prior to the software revolution, it was brick-and-mortar book stores like Borders. The largest provider of video services, Netflix, is a software company. Previously, you rented physical video cassette tapes at Blockbuster. The music we listen to today is stored digitally as a file, distributed through software, and made audible through software. The best recruiting company, LinkedIn, is a software company. Some of the best movies are created by Pixar, a software company. You get the idea, I’ll stop here.\nWhile software implementations of problem solving have upended many industries, the way we build and use software, and the types of problems we can solve with it, is itself being upended, thanks to the advances in large-language models (LLMs) like ChatGPT, Claude, Gemini, and others.\nThe shift toward computational thinking and the importance of solving problems through software has become most evident in 2024, when Nobel prizes in Physics and Chemistry were awarded not to scientists in those fields, but to computer scientists and artificial intelligence researchers who developed the foundational computational methods that helped to advance Physics and Chemistry (Figure 1.4 and Figure 1.5).\n\n\n\n\n\n\nFigure 1.4: 2024 Nobel Prize winners in Physics\n\n\n\n\n\n\n\n\n\nFigure 1.5: 2024 Nobel Prize winners in Chemistry\n\n\n\nDemis Hassabis, for example, is the CEO of Google DeepMind, the company behind AI projects such as AlphaGo, the reinforcement-learning trained system that accomplished what was thought impossible for a computer to do: beat the best Go player in the world.\nGeoffrey Hinton is a leading figure in research on artificial neural networks and deep learning. He is often considered the “Godfather of AI”. He is co-author of a 1986 paper that popularized back-propagation, an algorithm that efficiently computes the gradients in a neural network with many layers.\nBreaking with tradition, the Nobel committee awarded these prizes not to scientists who developed grand new theories of how the world works, but to scientist who develop the computational tools that help us develop grand new theories of how the world works.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#sec-intro-qt",
    "href": "intro.html#sec-intro-qt",
    "title": "1  Introduction",
    "section": "1.2 Quantitative Thinking (QT)",
    "text": "1.2 Quantitative Thinking (QT)\nQuantitative thinking (QT) is a problem-solving technique, like computational thinking. It views the world through measurable events, and approaches problems by analyzing quantitative evidence. At the heart of QT lies quantification, representing things in measurable quantities. The result is data in its many forms.\nThe word quantification is rooted in the Latin word quantus, meaning “how much”. The purpose of quantification is to express things in numbers.\nWhen dealing with inherently measurable attributes such as height or weight, quantification is simple. We need an agreed-upon method of measuring and a system to express the measurement in. The former might be an electronic scale or an analog scale with counterweights for weight measurement, a ruler, yardstick, or laser device for height measurements. It seems obvious to report weights in metric units of milligrams, grams, pounds (500 grams), kilograms, and tons or in U.S. Customary units of ounces, pounds (16 ounces), and tons. As long as we know which measurement units apply, we can all agree on how heavy something is. And we need to keep in mind that the same word can represent different things: a metric pound is 500 grams, a U.S. pound is 453.6 grams. But wait, there is more: Apothecaries’ weights are slightly different, a pound a.p. is 12 ounces. And in some fields, weights are measured entirely differently, diamonds are measured in carats (0.2 grams). In the International System of Units (SI), weight is measured in Newtons, which is gravitational force on a mass, equivalent to kg * m /s2. As long as we know what units are used to report a weight, we can convert it into whatever system we want to use. So we could say that this attribute is easily quantifiable.\n\nUncertainty\nWhen I hop on the scales in the bathroom in the morning, I usually take two or three measurements in quick succession. They rarely are identical, differing by a fraction of a pound. Day-to-day variation could be understandable, our weight does change over time. But second-to-second variation, that seems odd. It seems unlikely that I gained or lost a quarter pound over the last 5 seconds.\nQuantifying things is associated with uncertainty that is introduced through various forms of variability. My weight measurement varies from one measurement to the next because of my posture, movement on the scales, and the performance of the scales mechanism itself. Not because my actual weight differs. This type of variability is called measurement error. If we measure the weights of students in a classroom another source of variability is introduced, subject-to-subject variability. If we randomly choose a classroom from the school, the measurements also represent classroom-to-classroom variability, since repeating the process and selecting a different classroom will yield a different number.\nIn the presence of uncertainty, quantities are not knowable a priori. But if the uncertainty itself can be quantified, then the quantity of interest is predictable. I am unable to say what the average weight is of a student in a freshman class. But by measuring weights and quantifying uncertainty in the observations I can predict with a high level of confidence that the average freshmen students’ weight is between this much and that much (now attach your favorite weight units).\nIt is one of humanities’ great advances that we are not only able to represent concepts in numbers, but that we can quantify uncertainty itself. Probability and statistics enable us to learn from uncertain events and measurements. This adds to our vocabulary of lengths, weights, volumes, five-star ratings, and so on, the terms prediction, forecast, likelihood, odds, chance, and probability.\nA meteorologist forecasting a 30% chance of rain tomorrow is quantifying the likelihood of an event. We all know how to operationalize this forecast. The higher the number, the more likely we will need an umbrella the next day. Interestingly, while we have developed intuition about “the chance of rain”, many do not know how to correctly interpret a statement such as “30% chance of rain”. It does not mean that 30% of the area covered by the forecast will see rain. It does not mean that on days like today, 30% of them will have a rain event. Rather, it means that there is a 0.3 probability that any point in the forecast area will see a measurable amount of rain (usually 0.01 inches or more).\nAnother interpretation flows from the fact that weather forecasts are based on models that simulate weather conditions based on inputs. To account for the inherent uncertainty in measuring the inputs, multiple scenarios (simulations) are run. a 30% chance of rain means that 30% of the simulations predicted rain for the forecast area.\n\nBy applying statistical principles in the analysis of data uncertainty can be reduced. More informed insights about the data are then possible. Suppose we want to measure the average amount of an attribute in a population—say, the average years of postgraduate education. The population is too large to visit with every member so we instead quiz only a smaller number about their education. If we randomly sample one person from the population, we get a statistically valid estimate for the entire population. If they have 2 years of postgraduate education, our best guess for the average amount of post-graduate education in the entire population is 2 years. However, we have not reduced the uncertainty at all, the single measurement is as uncertain as the variability of postgraduate education years in the population. Suppose this variability can be quantified with the amount \\(X\\). If we repeat the process of randomly sampling persons \\(n-1\\) more times and computing the average across the \\(n\\) measurements—this is called the sample average—we get a much better estimate of the average number of years of postgraduate education in the population. It turns out that the sample average so obtained has uncertainty \\(X/n\\). In other words, we can make our statement about the population quantity of interest arbitrarily precise by sampling a large number of people from the population.\nFor attributes with large variability \\(X\\) it will take a larger sample size \\(n\\) to achieve the same level of precision compared to attributes with less variability. If the attribute does not vary at all in the population (\\(X=0\\)), then a single sample is sufficient. In the population of apartment renters there is no variability in the attribute renter, but there is variability in the attribute amount of rent late.\n\n\nBenefits of Quantification\nThe first obvious benefit of quantification is to make information amenable to mathematical and statistical operations. When mathematical or statistical calculations are concerned, any type of data will eventually be represented as numbers. A photograph turns into row and column indices of pixels and three-number triplets of red, green, and blue intensities. A sophisticated large language model that processes textual information converts the text into numeric representations, a process called encoding.\nHuff (1954), in one of the most widely published statistics texts, How to Lie with Statistics states\n\nMany a statistic is false on its face. It gets by only because the magic of numbers brings about a suspension of common sense.\n\nAccording to one view, the de-contextualized and value-free mathematical symbols used in statistical analyses assist in achieving objectivity, stability, and fairness in decisions. Quantification is a method of standardization that summarizes and reduces concepts to their essence and allows us to make better decisions.\nObjective metrics by which to measure allows us to establish rank and status. Status of nations can be measured by GDP (Gross Domestic Product). A countries’ portion of global GPD is one of the criteria for G20 membership. Quantified status is a much better solution than determining status by sending soldiers across borders.\nQuantification allows us to express relationships: ranking, ordering, and measuring proximity. As we will see in a later chapter, sorting and searching are fundamental. As an exercise observe how many times a day you encounter sorted lists, rankings, top-ten results, best-of lists, most-preferred lists and other forms of arranging information by a relevance metric. Google search would not be so successful if searching would not be combined with ranking results by relevance.\n\n\n\nTypes of Data\n\n\nSurrogacy\n\nFrom quantification to metric\n\n\nManaging the metric\n\n\n\nFigure 1.1: Benz Patent-Motorwagen, the first automobile.\nFigure 1.3: A recipe for pumpkin soup is an algorithm.\nFigure 1.4: 2024 Nobel Prize winners in Physics\nFigure 1.5: 2024 Nobel Prize winners in Chemistry\n\n\n\nAndreessen, Mark. 2011. “Why Software Is Eating the World.” https://a16z.com/why-software-is-eating-the-world/.\n\n\nHuff, Darrell. 1954. How to Lie with Statistics. W.W. Norton & Company, New York.\n\n\nTent, M. B. W. 2006. The Prince of Mathematics: Carl Friedrich Gauss. CRC Press, Boca Raton, FL.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "cholera.html",
    "href": "cholera.html",
    "title": "2  Case Study: Cholera in Soho, London, 1854",
    "section": "",
    "text": "2.1 Two Snows\nIn 1854, a severe outbreak of cholera occurred near Broad Street in Soho, London, killing over 600 people. The outbreak was studied by John Snow, considered one of the founders of modern epidemiology. No, not the Jon Snow you might be thinking of, Lord Commander of the Night Watch (Figure 2.1 (b)), but the John Snow in Figure 2.1 (a).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Case Study: Cholera in Soho, London, 1854</span>"
    ]
  },
  {
    "objectID": "cholera.html#two-snows",
    "href": "cholera.html#two-snows",
    "title": "2  Case Study: Cholera in Soho, London, 1854",
    "section": "",
    "text": "(a) John Snow. Source: Wikipedia\n\n\n\n\n\n\n\n\n\n\n\n(b) Jon Snow. Source: Wikipedia\n\n\n\n\n\n\n\nFigure 2.1: Famous John/Jon Snows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Case Study: Cholera in Soho, London, 1854</span>"
    ]
  },
  {
    "objectID": "cholera.html#visualization",
    "href": "cholera.html#visualization",
    "title": "2  Case Study: Cholera in Soho, London, 1854",
    "section": "2.2 Visualization",
    "text": "2.2 Visualization\nFigure 2.2 shows the map drawn by John Snow, recording the number of cholera cases with stacked bars at the location where cholera cases occurred (click on the map to zoom in). Also shown on the map as black circles and annotated as “PUMP” are the public water pumps throughout the city. The high number of cholera cases on Broad Street stands out, and they seem to be clustered near the location of the Broad Street Pump (Snow 1855, 46).\n\n\n\n\n\n\nFigure 2.2: John Snow’s original cholera map from Soho, London in 1854.\n\n\n\nCholera had been a major problem in the city, thousands had died during previous outbreaks. The prevailing theories of the cause of cholera were (i), airborne particles, called miasma that rose from decomposing organic material and (ii), an as of yet unidentified germ. According to the miasma theory, cholera is contracted by breathing bad air. John Snow adhered to the germ theory and believed that it was transmitted through contaminated water.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Case Study: Cholera in Soho, London, 1854</span>"
    ]
  },
  {
    "objectID": "cholera.html#data-validation",
    "href": "cholera.html#data-validation",
    "title": "2  Case Study: Cholera in Soho, London, 1854",
    "section": "2.3 Data Validation",
    "text": "2.3 Data Validation\nTalking to residents, Snow identified the public water pump on Broad Street to be the source of the outbreak. He failed to identify the germ under the microscope but came to the conclusion based on the pattern in the data and conversations with residents. Investigating on the ground, he found that nearly all deaths were in the vicinity of the Broad Street Pump or by people who had consumed water from the pump (Snow 1855, 47):\n\nIt will be observed that the deaths either very much diminished, or ceased altogether, at every point where it becomes decidedly nearer to send to another pump than to the one in Broad street. It may also be noticed that the deaths are most numerous near to the pump where the water could be more readily obtained.\n\nHe persuaded local authorities to remove the handle from the pump to prevent access to the water. The mortality rate declined after that, but it is believed that the outbreak was already in decline as people had fled the area.\n\n\n\n\n\n\nRemoving the handle\n\n\n\n“Removing the handle” is now a term in epidemiology for the removal of a harmful agent from the environment. When epidemiologists look for simple answers to questions about epidemics, they ask “Where is the handle to this pump?” (Adhikari, DeNero, and Wagner 2022).\n\n\nThere were some data points (outliers?) that did not agree with the hypothesis that proximity to the Broad Street pump resulted in more cholera incidences. At the intersection of Broad Street and New Street was the Lion Brewery; there were no cholera cases at the brewery although it used water from the Broad Street pump. It turns out that the workers there were protected from cholera by virtue of a daily beer allowance. The cholera bacteria is killed in the brewing process making the beer safe to drink. Drinking beer instead of the contaminated water saved the workers from cholera. What appears as an outlier to the model actually reinforces it.\nAdhikari, DeNero, and Wagner (2022) discuss other data points that appeared initially as anomalies and ended up implicating the public pump on Broad Street:\n\nThere were deaths in houses closer to the Rupert Street pump than the Broad Street pump. It was more convenient for those residents to use the Broad Street pump due to the street layout.\nDeaths in houses several blocks away from the Broad Street pump were linked to children who drank from the Broad Street pump on their way to school.\nJohn Snow was initially puzzled by two isolated deaths in the Hampstead area, far from Soho. He learned that the deceased had once lived in Broad Street. Because they liked the taste, they had water from the Broad Street pump delivered to Hampstead every day.\n\nThe well accessed by the Broad Street pump was contaminated with fecal bacteria that leaked into the well from a nearby cesspit. Sewage from the house of a cholera victim had contaminated the well.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Case Study: Cholera in Soho, London, 1854</span>"
    ]
  },
  {
    "objectID": "cholera.html#sec-cholera-deeper",
    "href": "cholera.html#sec-cholera-deeper",
    "title": "2  Case Study: Cholera in Soho, London, 1854",
    "section": "2.4 Toward Causality",
    "text": "2.4 Toward Causality\nThe evidence that the contaminated well water at the Broad Street pump caused the high rate of cholera in that neighborhood and among those who consumed the water is strong. Is it conclusive, however? Have we ruled out any other explanation beyond a reasonable doubt?\nThere could be other explanations for the higher cholera incidence rate in the Broad Street neighborhood compared to other areas of London. Maybe the diet is different among the residents of that poorer area. Maybe their occupations expose them to harmful agents at work. Maybe there is something different in the way their houses were constructed.\nWhile we know today that the bacterium Vibrio cholerae causes cholera, that discovery was not made until 1883 and John Snow had failed to identify a “germ” when he studied the Broad Street pump water. The prevailing miasma theory of infection from airborne particles also did not support Snow’s findings. While his data, visualization, and analysis showed a strong association between cholera and proximity to the Broad Street pump, a deeper analysis was necessary to convince his contemporaries.\nTo establish cause and effect and prove that a variable causes an outcome, modern science would design and run an experiment, provided it is ethically and technically possible. In such an experiment one would control for all other factors except the one hypothesized to cause the outcome. One method of controlling these confounding factors is by randomly assigning the conditions of interest to people and to observe what happens. Exposing folks deliberately to contaminated water that could harm or even kill them is not justified. Fortunately, John Snow found a real-life experiment with perfect conditions to establish cause and effect between cholera and water contamination.\nHe studied the cholera incidences among recipients of water from two water supply companies. The Lambeth company used water from the River Thames drawn upriver from sewage discharge and the Southwark & Vauxhall company drew water below the discharge. Snow also established that for all intents and purposes the households receiving water from either company were indistinguishable; in statistical terms they were comparable. The only thing that differentiated the two groups was the water supplier. Snow (1855, 75) wrote\n\nIn many cases a single house has a supply different from that on either side. Each company supplies both rich and poor, both large houses and small; there is no difference in the condition or occupation of the persons receiving the water of the different companies…As there is no difference whatever either in the houses or the people receiving the supply of the two Water Companies, or in any of the physical conditions with which they are surrounded, it is obvious that no experiment could have been devised which would more thoroughly test the effect of water supply on the progress of Cholera than this, which circumstances placed ready made before the observer.\n\nTable 2.1 is based on Snow (1855, 80) and covers the period from January 1 to December 12, 1853. The cholera death rate on a per 10,000 house basis is almost 14 times higher in households supplied by Southwark & Vauxhall compared to those who received their water from Lambeth.\n\n\n\nTable 2.1: Cholera incidences and rates for two water supply companies leading up to the 1854 outbreak.\n\n\n\n\n\n\n\n\n\n\n\nWater Supplier\nNo. of Houses\nCholera Deaths\nDeaths per 10,000 Houses\n\n\n\n\nSouthwark & Vauxhall1\n40,046\n286\n71\n\n\nLambeth\n26,107\n14\n5\n\n\n\n\n\n\nIn all of London there were 563 deaths from cholera in the same period. In other words, 50% of the deaths took place among customers of the Southwark & Vauxhall company. Ouch.\nFor the first seven week period of the 1854 outbreak, Snow (1855, 86) recorded the death rates in Table 2.2\n\n\n\nTable 2.2: Cholera incidences and rates during the first seven weeks of the outbreak. The death rate in the rest of London was reported as 59 in Table IX of Snow (1855), but calculates to 55 deaths per 10,000.\n\n\n\n\n\n\n\n\n\n\n\nWater Supplier\nNo. of Houses\nCholera Deaths\nDeaths per 10,000 Houses\n\n\n\n\nSouthwark & Vauxhall1\n40,046\n1,263\n315\n\n\nLambeth\n26,107\n98\n37\n\n\nRest of London\n256,423\n1,422\n\\(55^*\\)\n\n\n\n\n\n\nIn statistical terms, such a difference in the death rates is highly significant, meaning that if there is no difference in the water quality between the suppliers, such a discrepancy would virtually never happen. The only reasonable explanation for the higher death rate, since differences between the groups receiving the water have been ruled out, is the quality (contamination) of the Southwark & Vauxhall water.\n\n\n\nFigure 2.2: John Snow’s original cholera map from Soho, London in 1854.\n\n\n\nAdhikari, Ani, John DeNero, and David Wagner. 2022. Computational and Inferential Thinking: The Foundations of Data Science. 2nd Ed. https://inferentialthinking.com/chapters/intro.html.\n\n\nSnow, John. 1855. On the Mode of Communication of Cholera, 2nd. Ed. John Churchill, London. https://archive.org/stream/b28985266#page/n3/mode/2up.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Case Study: Cholera in Soho, London, 1854</span>"
    ]
  },
  {
    "objectID": "datascience.html",
    "href": "datascience.html",
    "title": "3  Data Science—CT + QT",
    "section": "",
    "text": "Quotes\n\n\n\n\nIt would be nice if we could just plug data into a statistical model,\ncrunch the numbers, and take for granted that it was a good\nrepresentation of the real world.\nNate Silver, The Signal and the Noise",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Science---CT + QT</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html",
    "href": "dataliteracy.html",
    "title": "5  Data Literacy",
    "section": "",
    "text": "5.1 Uncertainty",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html#sec-literacy-signal-noise",
    "href": "dataliteracy.html#sec-literacy-signal-noise",
    "title": "5  Data Literacy",
    "section": "5.2 Signal and Noise",
    "text": "5.2 Signal and Noise\nSeparating the signal from the noise is a key objective in all data analysis. The signal represents the systematic, non-random effects in the data. Data scientists and statisticians define the noise as the unpredictable randomness around the signal. A slightly different, and also useful, definition of noise stems from intelligence analysis. The signal is the information we are trying to find, the noise is the cacophony of other information that obscures the signal. That information might well be a signal for something else but it is irrelevant or useless for the event the intelligence analyst is trying to predict.\nInformation not being relevant for the signal we are trying to find is the key. In the view of the statistician, that information is due to random events.\nFinding the signal is not trivial, different analysts can arrive at different models to capture it. Signals can be obscured by noise. What appears to be a signal might just be random noise that we mistake for a systematic effect.\n\n\nExample: Theophylline Concentration\n\n\nFigure 5.1 shows the concentration of the drug theophylline over 24 hours after administration of the drug in two groups of patients. There are 98 data points of theophylline concentration and measurement time. What are the signals in the data? What is noise?\n\n\n\n\n\n\n\n\nFigure 5.1: Theophylline concentration over time in two groups of patients.\n\n\n\n\n\nThe first observation is that the data points are not all the same over time, otherwise they would fall on a horizontal straight line: there is variability in the data. Separating signal and noise means attributing this variability to different sources: some systematic, some random.\nFocusing on either the open circles (group 1) or the triangles (group 2), you notice that points that are close in time are not necessarily close in the concentration measurement. Not all patients were measured at exactly the same time points, but at very similar time points. For example, concentrations were measured after about 7, 9, and 12 hours. The differences in the concentration measurements among the patients receiving the same dosage might be due to patient-to-patient variability or measurement error.\nFocusing on the general patterns of open circles and triangles, it seems that the triangles appear on average below the average circle a few hours after administration. Absorption and elimination of theophylline appears to behave differently in the two groups.\nMuch of the variability in the data seems to be a function of time. Shortly after administering the drug the concentration rises, reaches a maximum level and then declines as the drug is eliminated from the body. Note that this sentence describes a general overall trend in the data here.\nWhich of these sources of variability are systematic—the signals in the data— and which are random noise?\n\nPatient-to-patient variability within a group at the same time of measurement: we attribute this to random differences among the participants.\nPossible measurement errors in determining the concentrations: random noise\nOverall trend of drug concentration over time: signal\nDifferences among the groups: signal\n\nThese assignments to signal and noise can be argued. For example, we might want to test the very hypothesis that there are no group-to-group differences. If that hypothesis is true, any differences between the groups we discern in Figure 5.1 would be due to chance; random noise in other words.\nThe variability between patients could be due to factors such as age, gender, medical condition, etc. We do not have any data about these attributes. By treating these influences as noise, we are making important assumptions that their effects are irrelevant for conclusions derived from the data. Suppose that the groups refer to smokers and non-smokers but also that group 1 consists of mostly men and group 2 consists of mostly women. If we find differences in theophylline concentration over time among the groups, we could not attribute those to either smoking status or gender.\n\n\nA common reason to mistake signal for noise is overfitting a model, a concept we return to in Section 5.5.1.\nAnother reason is if there is simply no signal at all. Figure 5.2 is taken from Silver (2012, 341) and displays six “trends”. Four of them are simple random walks, the result of pure randomness. Two panels show the movement of the Dow Jones Industrial Average (DJIA) during the first 1,000 trading days of the 1970s and 1980s. Which of the panels are showing the DJIA and which are random noise?\n\n\n\n\n\n\nFigure 5.2: Figure 11-4 from Silver (2012), Random walk or stock market?\n\n\n\nWhat do we learn from this?\n\nEven purely random data can appear non-random over shorter sequences. We can easily fall into the trap of seeing a pattern (a signal) where there is none. After drawing two unlikely poker hands in a row there is not a greater chance of a third unlikely hand unless there is some systematic effect (cards not properly shuffled, game rigged). Our brains ignore that fact and believe that we are more lucky than is expected by chance.\nData that contains clear long-run signals—the stock market value is increasing over time—can appear quite random on shorter sequences. One a day to day basis predicting whether the market goes up or down is very difficult. In the long run ups and downs are almost equally likely. Upswings have a slight upper hand and on average are greater than the downswings, increasing the overall value in the long term. Traders who try to beat the market over the short run have their work cut out for them.\n\nBy the way, panels D and F in Figure 5.2 are from actual stock market data. Panels A, B, C, and E are pure random walks. It would not be surprising if investors would bet money on “trend” C.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html#sec-literacy-accuracy-precision",
    "href": "dataliteracy.html#sec-literacy-accuracy-precision",
    "title": "5  Data Literacy",
    "section": "5.3 Accuracy and Precision",
    "text": "5.3 Accuracy and Precision\nThe terms accuracy and precision are often used interchangeably. In the context of measurement and data analysis they mean different things and the distinction is important.\nWhen talking about measuring devices, accuracy and precision are defined as\n\nAccuracy: How close are measurements to the true value\nPrecision: How close are measurements to each other\n\nWhen folks say that something is precise, what they often mean is that it is accurate. For example, when you measure something that is 8 feet long with a tape measure and the tape reads 8 feet, then it is accurate. If you repeat the measurement several times and all readings are close to 8 feet, then the tape (and you as its operator) is precise.\nPrecision refers to the repeatability of a method, accuracy refers to its proximity to a target value.\nTo demonstrate the difference between accuracy and precision, the dart board bullseye metaphor is helpful. Figure 5.3 shows four scenarios of shooting four darts each at a dart board. Suppose we are trying to hit the bullseye in the center of the board; it is the true value we are trying to measure.\n\nPattern A is the result of a thrower who is neither accurate nor precise. The throws vary greatly from each other (lack of precision), and the average location is far from the bullseye (inaccurate).\nPattern B is the result of a thrower who is inaccurate but precise. The throws group tightly together (high precision) but the average location misses the bullseye (the average distance from the bullseye is not zero).\nPattern C is typical for a player who is not precise, but accurate. The throws vary widely (lack of precision) but the average distance of the darts from the bullseye is close to zero—on average the thrower hits the bullseye.\nPattern D is that of an accurate and precise player; the darts group tightly together and are centered around the bullseye.\n\n\n\n\n\n\n\nFigure 5.3: Accuracy and precision—the dart board bullseye metaphor.\n\n\n\nAnother way to phrase accuracy and precision are in terms of the distribution of the measurements. Accuracy is about the average (central tendency) of the values, precision is about their variability. A statistical method that is not accurate—does not hit the target on average—is said to be biased.\n\nWhy do we worry about the distinction of precision and accuracy?\nIf we have a choice among different methods of drawing conclusions from data, we would opt for the one that is most precise and most accurate. To decide whether to buy, hold, or sell stock of company X, it would be great if we can forecast the stock value accurately and precisely. Imagine that you are the coach of the dart team. It is the end of the tournament, your team has one last dart left to throw; the team that gets closest to the bullseye will win the tournament. Which of the four types of players would you ask to make the throw? The precise and accurate player D is the safe bet.\nUnfortunately, we often do not have the luxury of a uniformly optimal method that has no bias and highest precision among all methods. We often need to make a compromise, and that means we have to weigh precision and accuracy against each other.\nStatisticians historically resolve the tension by demanding that methods are accurate (have zero statistical bias). Among all competing methods in that collection they then choose the one that has the highest precision (smallest variance). That is a reasonable approach especially if accuracy is most important.\nHowever, it is possible that the most precise unbiased method is much more variable than a biased method. In the dartboard example, if player D has retired from the sport, then we might bet on player B for the last throw. She has a higher likelihood of getting close to the bullseye than the more erratic—but close on average—player C.\nWe also worry about the distinction between accuracy and precision because our confidence in statements about data should include both. The precision of a method translates into uncertainty about its results. An imprecise method leads to uncertain conclusions. Pundits who offer ostensibly expert opinions about topics frequently provide predictions without telling us how precise they are:\n\n“Candidate A is ahead of candidate B by three points.”\n“Inflation will decrease by half a point in the next quarter.”\n“60% of adults between 35 and 45 support this legislation.”\n“The average temperature on the planet will increase by 1.4 degrees centigrade by 2030”.\n\nThese statements let us tacitly assume that the prediction is accurate and infinitely precise. If accompanied by a measure of precision—that is, uncertainty—the message is much more nuanced:\n\n“Candidate A is ahead of candidate B by three points. The margin of error is +/- 5 points”.\n\nThe margin of error covers the possibility that candidate B is in the lead.\n\n“The average temperature on the planet will increase by 1.4 degrees centigrade by 2030”. The 95% prediction interval in 2030 ranges from 0.2 to 2.6 degrees.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html#sec-literacy-correlation",
    "href": "dataliteracy.html#sec-literacy-correlation",
    "title": "5  Data Literacy",
    "section": "5.4 Causation and Correlation",
    "text": "5.4 Causation and Correlation\nYou might have heard the saying “correlation is not causation.” What is meant by that?\nCausation implies that one thing is the result of another thing; they stand in a cause-and-effect relationship to each other. The gravitational pull of the moon on earth’s oceans causes the tides. An accident causes a traffic jam. Smoking causes an increase in the risk of developing lung cancer.\nCorrelation, on the other hand, is about establishing association between attributes. The weight of a person is correlated with their height. Taller people tend to be heavier but height alone is not the only factor affecting someone’s weight. Smoking is correlated with alcoholism but does not cause it.\nIn Chapter 2 we discussed the 1854 cholera outbreak in Soho, London and John Snow’s investigation. He found higher cholera incidences in houses closer to the Broad Street public water pump. There was at least an association between cholera cases and proximity to the pump. Did the pump—or more precisely the water from the pump or something in the water—cause cholera? Today we know that cholera is caused by the bacterium Vibrio cholerae, but that discovery was not made until 1883.\nWe experience correlation when one attribute changes with another. Figure 5.4 shows various patterns in which two continuous attributes might be correlated. When the correlation is positive, one attribute tends to increase as the other increases. If the correlation is negative, an increase in one attribute is associated with a decrease in the other attribute.\n\n\n\n\n\n\nFigure 5.4: Correlations of different strength and directions. The numbers above the point clouds indicate the strength and direction of the correlation\n\n\n\nCorrelations are measured by the correlation coefficient, which ranges from -1 to 1. These extremes are called perfect correlations and happen when all points fall on a perfect line, without variability about the line.\nIt seems obvious that just because two attributes vary with each other—are correlated—one should not infer that they are cause and effect of each other. Unfortunately, that leap of faith is often made and can lead to very problematic decisions.\n\n\n\n\n\n\nFigure 5.5: Chocolate consumption and number of Nobel laureates.\n\n\n\nFigure 5.5 displays the number of Nobel laureates per 10 million population against the chocolate consumption (in kg per capita and year) for various countries (Messerli 2012). An upward trend is clearly noticeable. A greater per-capita chocolate consumption is associated with a lager number of Nobel laureates. Whoa! If the two variables stand in a cause-effect relationship then we have a simple recipe to increase Nobel prizes: we all should eat more chocolate. While one can argue the benefits of chocolate for cognitive function, what we have here is a simple correlation. The two attributes, number of Nobel laureates per 10 million population and chocolate consumption per capita, are related. If one increases so does the other. But why?\nThis is an example of a spurious correlation. The variables are not really dependent on each other, a relationship is induced in some other way. In this particular example, the correlation was “found” by cherry-picking the data: only four years of chocolate consumption were considered on a limited number of chocolate products and no data prior to 2002 was used. The number of Nobel laureates is a cumulative measure that spans a much longer time frame.\nIt appears that the data were organized in such a way as to suggest a relationship between the variables.\nYou can find spurious correlations everywhere, without manipulating the data. Here are some examples and the reasons why the data appear correlated.\n\nExamples of Spurious Correlations\n\nCoincidence\nForecasting economic conditions is difficult and highly valuable. Since the end of World War II there have been only eleven economic recessions. On the other hand we are producing thousands of economic indicators. The government alone generates 45,000 economic statistics each year (Silver 2012, 185).\nSo it should not be surprising that when sifting through all those variables we find some that appear to go up or down together, just by coincidence.\nA famous example is the Super Bowl winning conference as an indicator of economic performance. Between 1967 and 1997, in years when the team from the original NFL won, the stock market went up by 14%. When a team from the original AFL won the stock market decreased by almost 10%. Through 1997, the Super Bowl winner “predicted” correctly the direction of the stock market in 28 out of 31 years (Silver 2012). Since 1998 the trend has reversed and the stock market is doing better when an AFL team won the Super Bowl. Coincidence during a period of time leads to mistake noise for signal.\nAnother example of coincidence being mistaken for correlation is Paul, the octopus who correctly predicted the winner in 2008–2010 international soccer matches 12 out of 14 times, an 85% accuracy. Since this success rate is unlikely to happen by chance, it was determined that Paul the octopus has divine powers. When Paul got it wrong in a 2010 FIFA World Cup game between Germany and Spain, the German fans called for Paul to be eaten and the Spanish Prime Minister offered Paul asylum.\n\n\nLatent variables\nA correlation between variables A and C can be induced by another variable, say B. If A is correlated with (or caused by) B and C is correlated (or caused by) B, then plotting A versus C indicates a correlation between the two variables. However, the relationship is induced by the latent variable B.\n\n\n\n\n\n\nFigure 5.6: Spurious correlation.\n\n\n\nLatent variables are often the real reason why things appear related when we deal with variables that depend on population size or common factors such as the weather or time. Figure 5.6 shows the close relationship over time between the number of high school graduates and donut consumption. More donut consumption appears related to more high school graduates. Notice that we are not plotting graduation rates, these would most likely not have any relationships with donut consumption. The latent variable at work in Figure 5.6 is the size of the population over time. As the population increases, more donuts are consumed and more people graduate from high school.\nA similar spurious correlation is that between ice cream sales and forest fires. Both increase during the summer heat and decrease in the winter.\nYou can imagine the horrible public policy decisions one would make by mistaken those spurious correlations for cause and effect.\n\n\nInduced correlation\nAnother interesting mechanism to induce correlation is by introducing a mathematical dependence between two attributes. A famous example is the relationship between birth rate and the density of storks.\n\n\n\n\n\n\nFigure 5.7: Storks and Babies\n\n\n\nIn central Europe a persistent myth is that storks bring babies. Movies were made about it! The origin of the association probably goes back to medieval days when conception was more common in mid-summer during the celebration of the summer solstice which is also a pagan holiday of marriage and fertility. The white stork is a migratory bird that flies to Africa in the fall and returns to Europe nine months later. Hence the connection was made that storks brought the babies.\nAlthough the myth has been debunked, there have been several studies of the connection between fertility and the stork abundance. Neyman (1952) describes a study of 54 counties that comprises the following attributes\n\n\\(W\\): Number of women of child-bearing age in the county (in 10,000)\n\\(S\\): Number of storks in the county\n\\(B\\): Number of babies born in the county\n\nSince it is likely that these numbers increase with the size of the county, the variables analyzed were \\(Y = B/W\\) and \\(X=S/W\\), the birth rate per 10,000 women and the density of storks per 10,000 women. A plot of these variables and a smooth estimate of their trend is shown in Figure 5.8.\n\n\n\n\n\n\nFigure 5.8: Storks and babies.\n\n\n\nIt certainly appears that the birth rate increases with the density of storks. Could the myth be true? Is something else going on?\nThe trend in Figure 5.8 is induced by expressing both variables as ratios with the same variable, \\(W\\), the number of women of child-bearing age. If \\(S\\) and \\(B\\) are unrelated, \\(S/W\\) and \\(B/W\\) now share information because they are expressed relative to another variable.\n\n\n\nEstablishing Causality\nLet’s return to the 1854 cholera outbreak and the question before John Snow: did something in the water of the Broad Street public water pump cause cholera? If so, this would explain the higher incidence rate of cholera in residences near the pump and it would also explain the other anomalies he found in the data (see Chapter 2).\nThe map Snow drew in 1854 (Figure 2.2) might be convincing to us, his contemporaries did not feel that way. For one, he could not prove that the Broad Street well water caused the cholera cases. And his hypothesis was inconsistent with the prevailing theory of the time, that cholera was caused by airborne particles (miasma) from dirty or decaying biological material.\nThe analysis of the cholera map established a correlation rather than causation because of the possibility of confounding factors: variables that can mask or distort the effect of other variables. In the 1960s it was shown that coffee drinkers had higher rates of lung cancer than non-coffee drinkers. Some thought this was implication of coffee as a cause of lung cancer. That is incorrect. The association is due to a confounding factor: coffee drinkers at the time were more likely to be also smokers. Coffee drinking was associated with lung cancer but does not cause the disease.\nIn the case of the 1854 cholera outbreak, there could have been confounding factors that caused cholera incidences in the Broad Street area to be higher, whether the water was or was not the cause of the disease. Maybe the residents of that poorer neighborhood had a different diet that caused the disease. Maybe they had occupations that made it more likely to be exposed to a harmful agent. Maybe. Maybe. Maybe.\nIn order to establish a causal link between two variables, the confounding factors must be accounted for—at least beyond a reasonable doubt. Otherwise there will always be some reason to believe another mechanism was at work.\nHow one goes about accounting for confounding factors depends on the domain. The first question is whether the factors are controllable in some form. If so, we can use experimentation to set up controlled environments in which the only thing that can reasonably explain the effects we are seeing are the factors we deliberately manipulate. This is the area of experimental design.\nIf you cannot manipulate and control factors in an experiment, maybe you are lucky to find data where the confounding factors have already been controlled for you. Sometimes real life runs these quasi-experiments for us and eliminates the confounding factors. Although the data is observational rather than experimental (see below), it can go a long way toward establishing causality. In Section 2.4 we discussed a second, deeper analysis John Snow conducted in which he compared cases between customers of the Lambeth and the Southward & Vauxhall water companies. For all intents and purposes the groups serviced by the two companies were identical except for the source of the water. Lambeth’s water was drawn upriver from sewage discharge into the River Thames and was cleaner than the water from Southwark & Vauxhall, which drew water below the sewage discharge. The much higher cholera incidence in the group supplied by Southwark & Vauxhall was sufficient evidence to implicate the water.\nIn domains and applications where experimentation is not possible and confounding factors are present, we try to establish causation by a process called causal inference. By studying which variables act on each other, causality can be inferred.\n\nObservational and experimental data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html#sec-literacy-bias-variance",
    "href": "dataliteracy.html#sec-literacy-bias-variance",
    "title": "5  Data Literacy",
    "section": "5.5 Bias and Variance Tradeoff",
    "text": "5.5 Bias and Variance Tradeoff\n\nOverfitting\n\n\nUnderfitting",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html#all-models-are-wrongsome-are-useful",
    "href": "dataliteracy.html#all-models-are-wrongsome-are-useful",
    "title": "5  Data Literacy",
    "section": "5.6 All Models are Wrong–Some are Useful",
    "text": "5.6 All Models are Wrong–Some are Useful\nIn a 1976 paper, George E.P. Box declared “All models are wrong” (Box 1976). Later, he added a qualification which turned into a frequently cited quote about modeling:\n\nAll models are wrong, some are useful. (Box and Draper 1987, 424).\n\n\nCompartmental Models in Epidemiology\nSIR (Susceptible–Infectious–Recovered) model is a standard class of compartmental models in epidemiology, describing how an infectious disease moves through a population. On the surface this makes sense: at each point in time an individual is in one of three states, called compartments:\n\nYou have not had the disease but you are susceptible to it (S compartment)\nYou are infected by the disease (I compartment)\nYou are recovered from the disease, or dead (R compartment)\n\nA vaccination, then, is a shortcut that moves an individual directly from the S to the R compartment, bypassing the infected state.\nHowever, there are a number of assumptions in the SIR model that can invalidate the model for some diseases and circumstances:\n\nThe disease progresses in only one direction, from S to I to R.\nEveryone is equally susceptible and behaves the same way\nEveryone is equally likely to be vaccinated, if a vaccine is available\nAll members of the populations intermingle at random\n\nThe rate at which the disease spreads through the population is measured by the basic reproduction number, \\(R_0\\). This number, which we became all too familiar with during the COVID-19 pandemic, measures the number of uninfected people expected to catch the disease from an infected individual. An \\(R_0\\) of 3 means that someone who contracts the disease is expected to pass it on to three other individuals. In the absence of vaccines or quarantines, any disease with \\(R_0 &gt; 1\\) will eventually spread to the entire population.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "dataliteracy.html#agent-based-models",
    "href": "dataliteracy.html#agent-based-models",
    "title": "5  Data Literacy",
    "section": "5.7 Agent-based Models",
    "text": "5.7 Agent-based Models\nA different tactic than to rely on sophisticatedly simple models that abstract the essence of the thing we wish to study is to simulate the process in all its complexity, essentially building a digital twin of the thing we wish to study.\nThat is essentially the approach taken in weather prediction. Rather than relying on statistical models that predict based on historical data, weather predictions are based on complex physical simulations of the atmosphere.\n\n\n\nFigure 5.3: Accuracy and precision—the dart board bullseye metaphor.\nFigure 5.5: Chocolate consumption and number of Nobel laureates.\n\n\n\nBox, George E. P. 1976. “Science and Statistics.” Journal of the American Statistical Association 71 (356): 791–99.\n\n\nBox, George E. P., and Norman R. Draper. 1987. Empirical Model-Building and Response Surfaces. John Wiley & Sons, New York.\n\n\nMesserli, F. H. 2012. “Chocolate Consumption, Cognitive Function, and Nobel Laureates.” New England Journal of Medicine 367: 1562–64.\n\n\nNeyman, Jerzy. 1952. Lectures and Conferences on Mathematical Statistics and Probability. Graduate School, Dept. of Agriculture, Washington.\n\n\nSilver, Nate. 2012. The Signal and the Noise: Why so Many Predictions Fail–but Some Don’t. Penguin Books.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Literacy</span>"
    ]
  },
  {
    "objectID": "intuition.html",
    "href": "intuition.html",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "",
    "text": "6.1 The Prisoner’s Dilemma\nSuppose that Andy and Brie are arrested as members of a criminal gang and held separately by the police. They cannot communicate. There is enough evidence to convict them on a lesser charge, but not on the principal charge. The police offers the following deal:\nHow should Andy and Brie behave to optimize their positions, that is, look out after their own interest?\nThe result of such a game is typically displayed in a payoff matrix that shows in each cell the payoff for the two players.\nThe “payoffs” are shown in the matrix as negative numbers, as they represent a penalty, years of imprisonment. The goal is to maximize the payoff, a number as large as possible.\nThe best situation for Andy is to testify when Brie remains silent. He would go free in this case (and does not mind Brie spending three years behind bars). Similarly, the best situation for Brie is to testify when Andy remains silent. These are the two diagonal cells in Table 6.1.\nThe situation does not play out as well for them if one testifies and the other also testifies. What is the best strategy?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#the-prisoners-dilemma",
    "href": "intuition.html#the-prisoners-dilemma",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "",
    "text": "If they both remain silent, they will each serve one year in prison.\nIf one testifies against the other, but the other one does not, the one who testified will be set free while the other serves three years in prison.\nIf Andy and Brie both testify against each other, they will each serve two years.\n\n\n\n\n\n\nTable 6.1: Expected payoffs in prisoner dilemma\n\n\n\n\n\n\n\n\n\n\n\nBrie remains silent\nBrie testifies\n\n\n\n\nAndy remains silent\n\\((-1, -1)\\)\n\\((-3, 0)\\)\n\n\nAndy testifies\n\\((0, -3)\\)\n\\((-2, -2)\\)\n\n\n\n\n\n\n\n\n\n\nNash Equilibrium\nThe Nash equilibrium is a concept in game theory. It applies to non-cooperative games where players compete against each other. In the equilibrium state, no player can gain an advantage by changing their strategy. This assumes that the other player’s strategies do not change.\nSuppose players Andy and Brie have chosen strategies A and B, respectively. In the Nash equilibrium, there is no other strategy available to Andy that would increase his expected payoff if Brie stays with strategy B. Similarly, there is no other strategy available to Brie that would increase her expected payoff from the game if Andy stays with strategy A.\nThe Nash equilibrium tells us not to consider player’s action in isolation. Instead, we need to take into account what other players are expected to do in evaluating a player’s choices.\n\nThe best outcome for either Andy and Brie would be to go free. But they do not know how the other one will behave. So what is the best strategy to play this game? Let’s rephrase testifying and remaining silent in terms of defecting and collaborating players of a game.\n\n\n\nTable 6.2: Expected payoffs in prisoner dilemma\n\n\n\n\n\n\nBrie collaborates\nBrie defects\n\n\n\n\nAndy collaborates\n\\((-1, -1)\\)\n\\((-3, 0)\\)\n\n\nAndy defects\n\\((0, -3)\\)\n\\((-2, -2)\\)\n\n\n\n\n\n\nIf Andy defects, his penalty will be less, regardless of whether Brie is collaborative or not (0 or 2 years compared to 1 or 3 years). The same applies to Brie, if she defects her penalty will be less regardless of what Andy does. The Nash equilibrium is that both players defect although they suffer worse penalties than if they had both cooperated.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#guarding-criminals",
    "href": "intuition.html#guarding-criminals",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.2 Guarding Criminals",
    "text": "6.2 Guarding Criminals\nSuppose you are guarding \\(n\\) criminals in an open field. You have one gun with a single bullet. You are a good shot and being fired at means death—the criminals know that. Their behavior is governed by the following rules:\n\nIf any of them has a non-zero probability of surviving, they will attempt to escape.\nIf a criminal is certain of death, they will not attempt to escape.\n\nHow do you guard the criminals and stop them from escaping?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nImagine there is only a single criminal, \\(n=1\\). Since he/she would definitely be shot at during an escape, they would face certain death and not escape.\nWhat happens if there are two criminals? If they both try to escape, there is a 50:50 chance to survive, hence they will both try to escape. To prevent that from happening you would tell one of the two (you do not need to tell both!) that you would shoot them, should they both attempt to escape. That criminal now faces certain death and will not escape. That brings you back to the situation with a single criminal.\nHow does this generalize to larger groups of criminals? Assign a number from 1 to \\(n\\) to the criminals and tell them that should any subgroup of them try to escape, the one with the highest number in the group will be shot.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#three-jars",
    "href": "intuition.html#three-jars",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.3 Three Jars",
    "text": "6.3 Three Jars\nThree opaque jars are sitting on a table. The jars are labeled “Apples”, “Oranges”, and “Apples & Oranges”. Unfortunately, all three are labeled incorrectly.\n\n\n\nThree opaque jars.\n\n\nYour task is to assign the labels correctly to the jars. What is the smallest number of fruit you have to choose in order to correctly label the three jars?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou choose one fruit from the jar that is labeled incorrectly as “Apples & Oranges”. If you pull an apple, you know this is the jar with the apples, otherwise it is the jar with the oranges. Now you have two jars left whose labels just need to be flipped since you were told that all three jars are labeled incorrectly.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#pattern-recognition-1",
    "href": "intuition.html#pattern-recognition-1",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.4 Pattern Recognition #1",
    "text": "6.4 Pattern Recognition #1\nFigure 6.1 shows a logic reasoning puzzle. The first row makes sense if the strange operator is addition, but that does not work for the next rows. You have to find the meaning of that operator, then apply the pattern to solve the last equation.\n\n\n\n\n\n\nFigure 6.1: Can you solve this?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe need to find a pattern that expresses the operations in terms of familiar algebra. If the operator in Figure 6.1 is interpreted as multiplication then we get 4, 10, 18, all smaller than the values on the right hand side. How much smaller? Exactly by the left-most number. The pattern that seems to apply to the first three rows is\n\nmultiply the two numbers\nthen add the number on the left\n\nApplying this pattern to the last row yields 96 as the solution (Figure 6.2).\n\n\n\n\n\n\nFigure 6.2: A solution.\n\n\n\nThis, by the way, is not the only solution. There are other patterns that will lead to a different result for the last row. Those patterns are equally valid. Can you find another pattern that yields a solution?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#pattern-recognition-2",
    "href": "intuition.html#pattern-recognition-2",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.5 Pattern Recognition #2",
    "text": "6.5 Pattern Recognition #2\nHere is a sequence of numbers.\n\\[\n\\begin{array}{c}\n1 \\\\\n11 \\\\\n21 \\\\\n1211 \\\\\n111221 \\\\\n312211 \\\\\n??\n\\end{array}\n\\]\nWhat is the next number in the sequence?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWhat is the pattern in the sequence of numbers?\n\nThe first row is the number 1, it is also “one one”.\nThe second row is the number 11, it is also “two ones”.\nThe third row is the number 21, it is also “one two and one one”.\n\nThe pattern is that the numbers for the following row are obtained by spelling out the numbers in the current row, then replacing the words with the numbers they represent. For example, take 1211 in the fourth row. Spelling it out gives “one one one two two ones”. Now replace the words with numbers: “111221”.\nThe missing entry at the end of the sequence is thus \\[\n13112221\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#birthday-problem",
    "href": "intuition.html#birthday-problem",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.6 Birthday Problem",
    "text": "6.6 Birthday Problem\nThis is a classical problem in probability, and a popular one because it is relatable yet somewhat counterintuitive. The probability is higher than what most people expect. It goes like this:\n\nWhat is the probability that in a group of \\(n\\) randomly chosen people, at least two share the same birthday?\n\n“Birthday” is meant as one of 365 days of the year, not adjusting for leap years. Also, we are not taking the birth year into account. A birthday for the purpose of this problem is April 10, or August 15, etc.\nThe standard version of the problem uses \\(n=23\\), because you can imagine yourself in a group of that size—a classroom, for example—and the probability of at least two shared birthdays is also relatable.\nHow likely do you think at least two people share a birthday in a group of 23?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe probability of at least two shared birthdays in a group of 23 is about 0.5; it is 0.05073, to be more exact. How do you interpret that? If you were to assemble groups of 23 randomly chosen people, than half of those groups would have at least two shared birthdays. Pretty high, eh?\nWhat happens to the probability of a shared birthday when the groups get larger? How about in a group of 35 people? The probability of a shared birthday increases to 0.814. In a group of 50 people, the probability is 0.97. In a group of 100, it is virtually certain that there are at least two identical birthdays, \\(p=0.999999\\). With only 10 people in a group, it would be surprising to have identical birthdays, but it is not a rare event, \\(p=0.117\\).\n\nFor those interested, how do you calculate those probabilities? First, whenever you see the expression “at least” in a probability statement, it is probably easier to calculate the probability of the complement event and subtract that from 1. \\[\n\\Pr(\\text{at least two identical birthdays}) = 1 - \\Pr(\\text{no matching birthdays})\n\\]\nWhat is the probability that no birthdays match in a group of \\(n\\)? You can compute this by considering the possible choices as people enter the group. The birthday of the first person can be chosen from 365 days, but the birthday for the second person has only 364 choices, otherwise we would have a match. Since the members of the group are chosen at random, the birthdays are independent and the probability of no matches is the product \\[\n\\Pr(\\text{no matches}) = \\frac{365}{365} \\times \\frac{364}{365} \\times \\cdots \\times \\frac{365-n+1}{365}\n\\]\nYou can write this in terms of factorials as \\[\n\\Pr(\\text{no matches}) = \\frac{1}{365^n} \\frac{365!}{(365-n)!}\n\\] Finally, the probability of at least two shared birthdays is \\[\n\\Pr(\\text{at least two shared birthdays}) = 1 - \\frac{1}{365^n} \\frac{365!}{(365-n)!}\n\\]\nIf you were to compute this, you’d run into problems because the factorials are larger than what a finite precision computer can represent. The following R function uses two tricks to compute the birthday probability efficiently:\n\nCompute the probability on the logarithmic scale, then exponentiate at the end\nUse the fact that for an integer \\(k\\), \\(k!\\) is \\(\\Gamma(k+1)\\), where \\(\\Gamma()\\) is the Gamma function.\n\nThe lgamma function in R computes the log of the Gamma function, and that gives us access to an efficient way to compute the components of the probability on the log scale.\n\nbirthday_prob &lt;- function(n) {\n   log_p &lt;- lgamma(365+1) - lgamma(365-n+1) - n*log(365)\n   return (1-exp(log_p))\n}\n\nbirthday_prob(10)\n\n[1] 0.1169482\n\nbirthday_prob(23)\n\n[1] 0.5072972\n\nbirthday_prob(35)\n\n[1] 0.8143832\n\nbirthday_prob(50)\n\n[1] 0.9703736\n\nbirthday_prob(100)\n\n[1] 0.9999997",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#minimum-cuts",
    "href": "intuition.html#minimum-cuts",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.7 Minimum Cuts",
    "text": "6.7 Minimum Cuts\nImagine that you hire a consultant to work for you for five days. At the end of each day you need to pay them 1/5th of a gold bar. You have a single gold bar (worth 5 fifths) and need to cut it up so you can pay the consultant at the end of each day.\n\n\n\n\n\n\nFigure 6.3: A gold bar that needs to be cut up.\n\n\n\n\nWhat is the minimum number of cuts that allow you to pay the consultant every day?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou need only two cuts to cut the gold bar into three pieces of sizes 1/5, 1/5, and 3/5.\n\n\n\n\n\n\nFigure 6.4: No more than two cuts are needed.\n\n\n\nThen you pay the consultant as follows:\n\nDay 1: give them a 1/5 gold bar\nDay 2: give them the second 1/5 gold bar\nDay 3: take back the two 1/5 bars and hand them the 3/5 bar\nDay 4: give them a 1/5 gold bar\nDay 5: give them the second 1/5 gold bar",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#when-to-choose-the-ticket",
    "href": "intuition.html#when-to-choose-the-ticket",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.8 When to Choose the Ticket",
    "text": "6.8 When to Choose the Ticket\nAn airline has a single seat open on a flight, but \\(n=100\\) standby passengers hoping to get on the flight. You are one of the passengers on standby. To be fair to all standby passengers, the airline decides to drop 100 equal-sized pieces of paper into a bucket. 99 of them are blank, one says “Last Seat”. The papers are folded and shuffled in the bucket.\nThe standby passengers queue and each passenger gets to pick one piece of paper without replacement—that is, they keep the slip and do not return it to the bucket. Also they cannot unfold and look at the slip until all of them re drawn. After the last slip is drawn the standby passengers announce who is the lucky person that drew the “Last Seat” by checking their slip.\nHere is the question: if you have your choice to pick first, second, last, or at any particular position in the queue, which position would you choose?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIt does not matter when you draw the paper if the pieces were properly shuffled. This is a completely random sample even if the sampling is done sequentially. Your chance of drawing the “Last Seat” slip is 1/100, whether you draw first, last, or at any other position in the queue.\nNote that this would be different if passengers would announce the result of their draws before the next draw. The conditional probability of choosing the “Last Seat” slip on the next draw increases with every bank slip that preceded.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#how-many-squares-on-a-chessboard",
    "href": "intuition.html#how-many-squares-on-a-chessboard",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.9 How Many Squares on a Chessboard",
    "text": "6.9 How Many Squares on a Chessboard\nA chess board is made up of eight rows and columns of black and white positions (Figure 6.5). How many squares are on a board?\n\n\n\n\n\n\nFigure 6.5: Chess board.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe quick answer is \\(8 \\times 8 = 64\\) squares. However, that is only part of the story. The entire board is a single square as well, made up of the 64 individual squares. And we could place all kinds of \\(2 \\times 2\\) squares inside the larger frame.\nIf you think about it for a bit there are \\(8^2\\) squares of size \\(1 \\times 1\\), \\(7^2\\) squares of size \\(2 \\times 2\\), \\(6^2\\) squares of size \\(3 \\times 3\\) and so on. The total number of squares on a chess board is\n\\[\n8^2 + 7^2 + 6^2 + 5^2 + 4^2 + 3^2 + 2^2 + 1^2 = 204\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#book-sorting",
    "href": "intuition.html#book-sorting",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.10 Book Sorting",
    "text": "6.10 Book Sorting\nSuppose you are working in a library and are sorting books from a box that contains 32 fiction (F) and 17 non-fiction (NF) books. A steady supply of new books is available to add to the box. Your sorting algorithm goes as follows:\n\nYou randomly choose 2 books from the box.\nBased on the types of books chosen you add another book from the supply to the box:\n\nif you choose two fiction books (F,F) you add a new fiction book to the box\nif you choose two non-fiction books (NF, NF) you also add a fiction book to the box\nif you choose one fiction and one non-fiction book (F,NF or NF,F) then you add a non-fiction book to the box.\n\n\nThe entire procedure is depicted in Figure 6.6.\n\n\n\n\n\n\nFigure 6.6: Book sorting routine. Source\n\n\n\nSince you add only one book to the box for every two books you remove, the box will eventually be empty. What is the type of the last book in the box? Is it a fiction or a non-fiction book?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number of books in the bin goes down by one with each cycle: two books are removed from the bin, one book is added. How does this affect the number of fiction and non-fiction books that remain?\nLet’s see how the number of non-fiction books in the bin changes in cases 1.–3. In the first case, there is no change. In the second case, the number of non-fiction books goes down by 2. In the third case, the number of non-fiction books also does not change: one is removed, one is added.\nSince the number of NF books initially is an odd number, 17, we can conclude that after each cycle the number of NF books remains an odd number. It can never be an even number. Which leads to the conclusion that if there is only one book left in the bin it must be a non-fiction book.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#inverted-triangle",
    "href": "intuition.html#inverted-triangle",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.11 Inverted Triangle",
    "text": "6.11 Inverted Triangle\nFigure 6.7 shows a triangle made from 10 coins. Can you change this into an upside-down triangle by moving only 3 coins?\n\n\n\n\n\n\nFigure 6.7: Inverting the coin triangle.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe solution is shown in Figure 6.8. First, focus on the seven coins in the center of the triangle. The original and the inverted triangle share these; they do not need to move at all. We can focus on the three coins at the edges.\n\n\n\n\n\n\nFigure 6.8: Moving the three coins.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#the-spare-tire",
    "href": "intuition.html#the-spare-tire",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.12 The Spare Tire",
    "text": "6.12 The Spare Tire\nYour car has four tires mounted to the wheels and a spare tire (S). That gives you five tires to work with. Each of the tires lasts at most 30,000 miles. If you can exchange tires among the five as many times as you wish, what is the furthest distance you can travel before you need to purchase a new tire?\nFigure 6.9 depicts the initial tire life prior to driving the first mile. All tires, including the spare (S) have the same life expectancy of 30,000 miles.\n\n\n\n\n\n\nFigure 6.9: Tire life before driving the first mile.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe maximum total distance the five tires could travel before they are all worn out is 30,000 x 5 = 150,000 miles. The minimum distance of travel before you have to buy at least one new tire is 30,000 miles; it is achieved if you do not use the spare tire and run down the four tires currently mounted.\nBy optimizing how you use the spare tire, there must be an achievable distance between 30,000 and 150,000 miles. The optimal strategy is to wear all tires equally and to use the spare tire as much as possible. But we cannot use the spare for more than 30,000 miles, same as with the other four tires.\nIf the four tires on the car are equally worn, we can go at most 150,000/4 = 37,500 miles. The strategy is to get 30,000 miles from each of the tires on the car and 4 times 7,500 = 30,000 miles from the spare tire. In other words, the spare will have to give each of the four tires a 7,500 mile break.\nFigure 6.10 shows how the spare tire is rotated for another tire after each leg of 7,500 miles. The right rear tire comes off after the fourth leg, it is worn out. The other tires still have 7,500 miles of life to go.\n\n\n\n\n\n\nFigure 6.10: Remaining tire life after 7,500, 15,000, 22,50, and 30,000 miles., miles",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#robot-triangle",
    "href": "intuition.html#robot-triangle",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.13 Robot Triangle",
    "text": "6.13 Robot Triangle\nThere are many versions of this basic puzzle, using ants, camels, and other animals. We use robots here, the puzzle goes like this. Three robots are placed at the corners of a triangle. A robot can choose to move along either side of the triangle that meet at its corner (Figure 6.11). What is the probability that any two robots will collide?\n\n\n\n\n\n\nFigure 6.11: Robot triangle.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEach robot has two possible movements, so there are a total of 2 x 2 x 2 = 8 possible moves on the triangle. There are two ways in which there won’t be any collisions, if all choose to go clockwise or counter-clockwise. In those cases they will follow each other around the triangle (Figure 6.12).\n\n\n\n\n\n\nFigure 6.12: Robots moving without running into each other.\n\n\n\nAny other choice of movements will result in at least one collision. So the probability of any collision if the robots choose their movements at random is 6/8 = 3/4. There is a 75% chance that any two robots will collide.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#truth-telling",
    "href": "intuition.html#truth-telling",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.14 Truth Telling",
    "text": "6.14 Truth Telling\nThis puzzle is about logic reasoning and not about probability. Surprisingly, it is related to the previous robot movement puzzle.\nConsider the following three statements:\n\nGavin says that Brian is a liar.\nBrian says that Jenn is a liar.\nJenn says that both Gavin and Brian are liars.\n\nWho is telling the truth and who is lying?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis puzzle is related to the robot movement in that there are \\(2^3 = 8\\) possible choices, each of the three characters could either be truthful or lying. It is different from the robot movement in that it is not a question of probability. While robots choose one of the two directions at random, our characters are either lying or telling the truth. We have to reason which one it is.\nWith 8 possible choices you can go about it by finding combinations that are inconsistent, a process of elimination.\nSuppose that Jenn tells the truth. Then Gavin and Brian are liars. According to Gavin’s statement, that would mean Brian is telling the truth. But Brian’s statement contradicts the assumption that Jenn tells the truth. Jenn must be a liar.\nIf Jenn is not telling the truth, there are three possibilities:\n\nGavin is truthful and Brian is not\nGavin is a liar and Brian is truthful\nBoth are truthful.\n\nLet’s look at the first option. If Gavin tells the truth than Brian is lying, which means Jenn would be truthful. We already ruled out this possibility. But if Gavin is not truthful, then 3. cannot be the case either.\nWe are down to the second option: Brian speaks the truth and the other two are liars. Let’s see if everything makes sense in this scenario: If Gavin does not speak the truth, then Brian is not a liar. Brian’s statement that Jenn is a liar is consistent with what we already found.\nConclusion: Only Brian is truthful.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#clock-made-with-matches",
    "href": "intuition.html#clock-made-with-matches",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.15 Clock Made With Matches",
    "text": "6.15 Clock Made With Matches\nYou have two wooden sticks and a box of matches. When a sticks is lit it will burn completely in exactly one hour. How do you use these ingredients to measure exactly 45 minutes?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLight the first stick on one end and light the second stick on both ends. Since an entire stick burns in one hour, the stick lit on both ends will burn down in 30 minutes (Figure 6.13).\n\n\n\n\n\n\nFigure 6.13: Initial lighting of sticks.\n\n\n\nAt that point light the first stick on the other end. This will double the speed with which that stick, now reduced to 30 minutes burn time, will burn.\nWhen the first stick is completely burned down, 45 minutes will have passed (Figure 6.14).\n\n\n\n\n\n\nFigure 6.14: After 30 minutes, light the other end of the first stick.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#two-stacks-of-cards",
    "href": "intuition.html#two-stacks-of-cards",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.16 Two Stacks of Cards",
    "text": "6.16 Two Stacks of Cards\nYou have two stacks of cards. The first is a regular 52-card deck. The second stack contains two regular 52-card decks, thus has 104 cards. Both stacks are shuffled well. You choose two cards in sequence and you win if they are both red. Would you prefer to choose from the 52-card stack or the 104-card stack?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou want to choose from the larger stack. The probability to draw two red cards in sequence from a stack of \\(n\\) cards (with \\(n/2\\) red ones) is \\[\n\\frac{n/2}{n} \\times \\frac{n/2-1}{n-1}\n\\] For the first draw the probabilities are identical: \\(26/52\\) and \\(52/104\\). But for the second draw the probabilities are \\[\n\\frac{51}{103}=0.495 &gt; \\frac{25}{51}=0.49\n\\]\nThere is a slightly higher chance to draw two red cards from the larger stack.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#rapid-fire",
    "href": "intuition.html#rapid-fire",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.17 Rapid Fire",
    "text": "6.17 Rapid Fire\nCowboy Billy carries a Colt single action 6 shooter revolver. When he fires all 6 shots in a row, the time between the first bullet and the last is 60 seconds. How long would it take him to fire 3 shots?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIt will take him 24 seconds to fire three shots. Wait, what?\nThe relevant pattern here is about the time elapsed between shots. If the shots are fired at regular intervals, then Billy will take 12 seconds between the six shots. 12 seconds after the first shot he fires the second bullet, 12 seconds after that he fires the third bullet.\nAnother way of thinking about this is the distance at which fence posts are placed. In a fence with six posts, the first one is at 0/5th total distance, the second post is located 1/5th of the total distance, and so on.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "intuition.html#crossing-the-river",
    "href": "intuition.html#crossing-the-river",
    "title": "6  Quantitative Intuition and Problem Solving",
    "section": "6.18 Crossing the River",
    "text": "6.18 Crossing the River\nA farmer is on his way back from the market, with him he has a fox, a chicken and some grain. To get home he needs to cross a river using a small boat that can accommodate only him and one of the other items. Unfortunately, if the fox is left alone with the chicken it will eat it. If the chicken is left alone with the grain, it will eat it. How can the farmer cross the river and bring home the fox, the chicken, and the grain?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis will take several trips across the river:\n\nHe takes the chicken across the river.\nHe returns in an empty boat and picks up the fox.\nHe takes the fox across the river and picks up the chicken.\nHe returns with the chicken in the boat and deposits it while picking up the grain.\nHe takes the grain across the river. Now he has the chicken on the near side of the river and the fox and the grain on the far side.\nHe returns in an empty boat and picks up the chicken.\nHe takes the chicken across the river, now all three items have crossed.\n\nThe trick is to take one item—here, the chicken—back and forth to make sure it is not alone with the item it would destroy.\n\n\n\n\n\n\nFigure 6.10: Remaining tire life after 7,500, 15,000, 22,50, and 30,000 miles., miles",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quantitative Intuition and Problem Solving</span>"
    ]
  },
  {
    "objectID": "predictions.html",
    "href": "predictions.html",
    "title": "7  Making Predictions",
    "section": "",
    "text": "7.1 Introduction\nIn The Signal and the Noise, Silver (2012, 52) cites a study at the University of Pennsylvania that found when political scientists claim that a political outcome had no chance of occurring, it happened about 15% of the time. And of the absolutely sure things they proclaimed, 25% failed to occur. Now we know that predictions are themselves uncertain, that is why polling results have a margin of error. But when you predict that something has a zero chance of happening, then you ought to be pretty confident in that, the margin of error should be small, definitely not more than 15%.\nThis is an example of a prediction that is not very good.\nIf a plane had a 29% of crashing, you would consider the risk of flying too high and stay on the ground. In the run-up to the 2016 presidential election, FiveThirtyEight predicted a 71% chance for Clinton to win the Electoral College and a 29% chance for Trump to win. This was a much higher chance of a Trump victory than the 1% to 15% chance many other models produced. As it turned out, the FiveThirtyEight model was much better than the models that treated the Clinton victory as a near certainty.\nSilver (2012) points out\nSometimes we predict things more accurately (small margin of error in the prediction) but we do not believe it or act on it. Predictions that contradict our intuition or preferred narrative can be ignored or explained away. Our personal judgment is not as good as you might think. We tend to overvalue our own opinion and this trend increases the more we know. 80% of doctors believe they are in the top 20% of their profession. More than half of them are clearly wrong.\nSo when a prediction does not come true, does the fault lie with the model of the world or the world itself? If there is a 80% chance of rain tomorrow, then you might see sunny skies. If, in fact, the long run ratio of days that have sunny skies when the forecast calls for an 80% chance of rain is 1 in 5, then the forecast model is correct. Compare the scenario to the following:\nIn the build-up of the the 2008 financial crisis, Standard & Poor gave CDOs, a type of mortgage-backed securities, a stellar AAA credit rating, meaning that there is only a 0.12 probability that they would fail to pay out (Silver 2012, 20). In reality, of the AAA-rated CDOS, 28% defaulted. Had the world of financial markets drastically changed to bring about such a massive change in default rates (200x!)? Or is it more likely, that the default models of the rating agencies were wrong? It was the latter.\nWe predict all the time. On the drive to work we choose this route over that route because we predict it has less traffic, fewer red lights, or we are less likely to get caught behind a school bus. We probably make this choice instinctively, without much deliberation, based on experience, instantaneously processing information about the time of day, weather, etc.\nYou might choose Netflix over Paramount+ one evening because you think it is more likely that you’ll find content that interests you. This is also a prediction problem. A company offers a customer a discount because it predicts that without an incentive the customer might leave for a competitor. Information about the weather consists of a status report of current conditions and a forecast.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Making Predictions</span>"
    ]
  },
  {
    "objectID": "predictions.html#sec-predict-intro",
    "href": "predictions.html#sec-predict-intro",
    "title": "7  Making Predictions",
    "section": "",
    "text": "“Most people fail to recognize how much easier it is to understand and event after the fact when you have all the evidence at your disposal. [] But making better first guesses under conditions of uncertainty is an entirely different enterprise than second-guessing.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrediction and Forecast\n\n\n\nTechnically, a prediction and a forecast are different things. In statistics, a prediction results from the application of a model to data. If the data falls outside of the range of observed training data, then it is referred to as a forecast, in particular when the prediction is about a future event.\nForecasting is also referred to as planning in the presence of uncertainty, taking a systematic, methodological approach. Predicting, on the other hand is any proclamation about things we do not know yet. We predict the outcome of a football game based on gut feeling or allegiance to a team, but we forecast the weather based on meteorological models.\nIn seismology, the distinction between prediction and forecast is taken very seriously. A prediction of an earthquake is a specific statement about when and where it will strike. A forecast, on the other hand is a statement of probability: there is a 60% chance of an earthquake in Northern Italy over the next fifty years. Leaning on this distinction, the U.S. Geological Service party line is that earthquakes cannot be predicted.\nFor the purpose of our discussion here, predicting and forecasting are interchangeable.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Making Predictions</span>"
    ]
  },
  {
    "objectID": "predictions.html#supervised-and-unsupervised-learning",
    "href": "predictions.html#supervised-and-unsupervised-learning",
    "title": "7  Making Predictions",
    "section": "7.2 Supervised and Unsupervised Learning",
    "text": "7.2 Supervised and Unsupervised Learning\nMaking predictions is probably the fundamental task of algorithms that process data by training some form of model. Statistical learning techniques can be categorized in broad strokes into supervised and unsupervised methods. The name stems from the concept of students learning in the presence of a teacher. In supervised learning the teacher knows the correct answer to problems, and can measure the discrepancy between truth and a student’s answer. In unsupervised learning there is no teacher to guide the quality of the answer. Instead, the student is trying to find patterns and associations in the data.\nThe two primary tasks in supervised learning are predictions and classifications. Classification problems involve assigning an observation to one of a set of possible outcome categories, for example, whether an animal is healthy or diseased, or choosing a word from a dictionary, or which one of the digits 0–9 a handwriting sample represents. Prediction in the sense of supervised learning is making a statement about the average of an attribute, for example, the monthly revenue or the weight of an animal.\nWe go on this detour of supervised/unsupervised learning and of prediction/classification to uncover that the process of prediction is fundamental to all these applications. Consider you are presented with a handwritten digit and you have trained a classification model in digit detection. The algorithm does not actually say which of the ten digits it was presented with. The algorithm will compute a vector of 10 quantities each between 0 and 1, and subject to the constraint that they sum to 1.\nHere is the vector for one observation \\[\n[0.00000, 0.00001, 0.00001, 0.00003, 0.00000, 0.00000, 0.00000, 0.99994, 0.00000, 0.00001]\n\\]\nand here is the vector for another observation\n\\[\n[0.00056, 0.00002, 0.00000, 0.00001, 0.00424, 0.74695, 0.18760, 0.00001, 0.00616, 0.05446]\n\\]\nThe first element of the vector corresponds to digit 0, the second to digit 1, and so on. Considering the first vector, how would you convert the numbers into a classification? Since the numbers are between 0 and 1, and sum to 1, it is tempting to interpret them as probabilities. The overwhelming evidence points at the 8th position in the vector with a large probability of 0.99994. The algorithm is almost certain that the digit is a “7”.\nIn the second case we see more of a spread in the probabilities. Digit “5” is considered most likely (probability 0.74695), but other digits also have a non-zero probability (“6” and “9”). Given the large probability for “6” we would probably classify the digit as a six.\n\n\n\n\n\n\nFigure 7.1: Digit classifications.\n\n\n\nFigure 7.1 shows the actual and classified digits for nine data points. The vectors shown above correspond to the probabilities for the images in the upper left and lower right corners. We are not surprised that the algorithm classified the first observation as a “7”. We are also not surprised that the sloppy “5” in the lower right corner could be mistaken for a “6” (which had the second largest probability).\nThe point of this example is twofold:\n\nThe process of classifying something through a statistical algorithm often goes first through a process of predicting a measure of confidence or likelihood associated with the possible outcomes. We then classify the observation into the category that has the highest probability. This is known as the Bayes Rule of classification and it can be shown to be optimal in the sense of achieving the greatest accuracy.\nWhen making predictions we need to think in terms of probabilities and uncertainties. Ultimately, the classification model will spit out one category and we interpret this as “the model says the digit is a seven”. In the case of the first observation, there is not much uncertainty with the prediction, as the model deems other choices very unlikely. In the second case we should appreciate that the algorithm decided on a “5”, but also that there is uncertainty in the prediction. We only know that the algorithm got it right because we know the author of the digit was writing a “5” (the label). As Silver (2012) puts it,\n\n\nOur brains, wired to detect patterns, are always looking for a signal, when instead we should appreciate how noisy the data is.\n\nA common task in unsupervised learning is finding patterns in the data that allow us to group the observations. The algorithm finds that observations are somehow similar and dissimilar based on their attributes. This process is called a cluster analysis and the result are a certain number of clusters formed from the training data. If a new observation comes along, we can assign it to one of the clusters by applying the clustering model. We predict which of the clusters the observation is closest to in the sense of the model. Again, prediction is the fundamental task by which we draw conclusions about new observations.\n\nPredictions are everywhere. We make them, consciously or subconsciously all the time. The human brain is a highly efficient pattern matching machine and we constantly make predictions about the world based on the patterns we receive. Predictions are at the heart of data processing, whether it is for the purpose of forecasting, classifying, or clustering (grouping).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Making Predictions</span>"
    ]
  },
  {
    "objectID": "predictions.html#bad-predictions",
    "href": "predictions.html#bad-predictions",
    "title": "7  Making Predictions",
    "section": "7.3 Bad Predictions",
    "text": "7.3 Bad Predictions\nSilver (2012, 20) summarizes the attributes bad predictions have in common:\n\nFocus on the signals that tell a story abou the world as we would like it to be, not how it really is.\nIgnore the risks that are most difficult to measure, although they pose the greatest risk to our well-being.\nMake approximations and assumptions that are much cruder than we realize.\nDislike (abhor) uncertainty, even if it is an integral part of the problem.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Making Predictions</span>"
    ]
  },
  {
    "objectID": "predictions.html#predicting-versus-measuring",
    "href": "predictions.html#predicting-versus-measuring",
    "title": "7  Making Predictions",
    "section": "7.4 Predicting versus Measuring",
    "text": "7.4 Predicting versus Measuring\n\nDestructive tests\nExpensive tests\nFuture performance",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Making Predictions</span>"
    ]
  },
  {
    "objectID": "predictions.html#things-that-are-notoriously-difficult-to-predict",
    "href": "predictions.html#things-that-are-notoriously-difficult-to-predict",
    "title": "7  Making Predictions",
    "section": "7.5 Things that are Notoriously Difficult to Predict",
    "text": "7.5 Things that are Notoriously Difficult to Predict\n\nNoisy Systems, Sparse Data\n\nLow signal-to-noise ratio\n\n\n\nChaotic Systems\n\nWeather\nEconomy\n\n\n\nComplex Systems\nComplex systems are those governed by the interaction of many separate individual parts. They can seem at once very predictable and very unpredictable. The laws governing earth quakes are well understood and the long-term frequency of a magnitude 6.5 earthquake in Los Angeles can be estimated well. But we are not very good at predicting earthquake activity.\nComplex systems periodically undergo violent and highly nonlinear phase changes from orderly to chaotic and back again. Bubbles in the economy and significant weather events such as hurricanes, tornadoes, or tsunamis are examples.\n\nEarthquakes\n\n\n\nNonlinear or Exponential Growth\n\nInfectious diseases\n\n\n\nSystems with Feedback Loops\nThe act of predicting can change the system being predicted. Economic predictions can change the way people have and that can affect the outcome of the prediction itself. Those changes can make the prediction more accurate or less accurate.\nSelf-fulfilling predictions, where the prediction reinforces the outcome, are common in political polling. A poll showing a candidate surging can cause voters to switch to the candidate from ideologically similar candidates. Or it can make undecided voters to finally get off the fence.\nAnother example of a self-fulfilling prediction is when increased media coverage of a medical condition leads to increased diagnosis of the condition. Not just because the condition is more prevalent, but because of increased attention people are more likely to identify symptoms and are doctors are more likely to diagnose them. The rise of autism diagnoses in the U.S. from 1992 to 2008 correlates highly with the media coverage of autism (Silver 2012, 218).\nWhen the police increase presence in an area where crime rate is believed to be high, they will report more incidences because of their presence and that will in turn increase the crime rate.\nA self-cancelling prediction works the opposite way, it undermines itself. When GPS systems became more commonplace, drivers were guided to routes which the systems thought had less traffic. If the systems cannot adjust in real time to the actual traffic density, the guidance can result in more traffic on the suggested routes.\n\n\n\nFigure 7.1: Digit classifications.\n\n\n\nSilver, Nate. 2012. The Signal and the Noise: Why so Many Predictions Fail–but Some Don’t. Penguin Books.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Making Predictions</span>"
    ]
  },
  {
    "objectID": "life_algorithms.html",
    "href": "life_algorithms.html",
    "title": "8  Algorithms to Live By",
    "section": "",
    "text": "8.1 Introduction\nIn the introduction we defined an algorithm as a set of repeatable step-by-step instructions to solve a particular problem. Algorithms are not necessarily the machinations of computer scientists and mathematicians—recall making pumpkin soup. We design and apply algorithms in every day life. You probably have a personal algorithm or two for brushing teeth or making the bed.\nAlgorithms are designed to perform a task in some optimal way. My dog applies the above algorithm to achieve the optimal sleeping arrangement—by his standard. Mathematicians and computer scientists have developed many algorithms to solve certain problems optimally. If you have to put five books on a shelf in order, you might not worry much about the sorting algorithm. When you have to sort 100,000 items choosing between a bubble, quick, or merge sort matters much more.\nCan we apply what mathematicians and computer scientists know about optimal algorithms to solve problems in everyday life? The discussion that follows draws on the book Algorithms to Live By by Christian and Griffiths (2017).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algorithms to Live By</span>"
    ]
  },
  {
    "objectID": "life_algorithms.html#introduction",
    "href": "life_algorithms.html#introduction",
    "title": "8  Algorithms to Live By",
    "section": "",
    "text": "Getting into bed: a dog’s perspective\n\n\n\n\n\nMy dog has developed an elaborate algorithm for nights when he wants to sleep in the bed. He starts out sleeping in his dog bed on the floor and the algorithm goes something like this:\n\nGet up and pretend there is something outside that needs his attention: a squirrel in a tree, a raccoon on the porch, a deer in the yard, etc.\nMake sure that I understand the severity of the threat and follow him to the living room. This can involve growling at the door to the deck, running back and forth between living room and bed room.\nI finally get up, follow him into the living room and open the door to the deck.\nAt this point he pretends to realize that there is no threat after all and we can go back to bed.\nHe follows me into the bedroom, positioning himself next to the bed in the unmistakable posture that says “lift me up on the bed please.”\n\nTo his credit, he could jump on the bed by himself and is going through this routine as a means to get permission. The algorithm is complicated, but it is a repeatable step-by-step recipe, and it works every time.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algorithms to Live By</span>"
    ]
  },
  {
    "objectID": "life_algorithms.html#optimal-stoppingthe-37-rule",
    "href": "life_algorithms.html#optimal-stoppingthe-37-rule",
    "title": "8  Algorithms to Live By",
    "section": "8.2 Optimal Stopping–The 37% Rule",
    "text": "8.2 Optimal Stopping–The 37% Rule\nSuppose you just landed a job at a Silicon-Valley startup company and are locating to San Francisco. Finding an apartment in San Francisco can be a rough experience: there is a lot of demand for a short supply. As a newcomer to town you do not have a good feeling for the market. What do typical apartments in your price range look like? What is available on the market?\nHere is the dilemma: you cannot procrastinate much when you see an available apartment; they go very fast. But if you choose the first available apartment you will miss out on better ones that you have not seen yet. If you pass on the first available apartment there is no guarantee that the next ones will be any better. But you need to look at least at a few of them to get a feeling for what is on the market. How else could you make an informed decision? But if you keep looking at apartments and pass on them you might end up with no apartment at all or you have to choose from what is left on the market. Is looking at 2 apartments enough? 20?\nThere are two ways in which you can fail: stop looking at apartments too early and stop looking too late. When you stop too early a better apartment goes undiscovered. If you stop too late you hold out for a better apartment that does not exist, you have passed on the best possible apartment already.\nThis is known as an optimal stopping problem. How much effort should you spend on looking at choices and when should you leap and make a decision?\nIt turns out that there is an answer. The optimal decision rule is to spend 37% of your budget on calibrating and looking at apartments to establish a standard. Then pick the next apartment that beats the standard. If your budget is one month to find an apartment, then you should look and calibrate for 11 days.\nWe can thank computer science for having an optimal solution to balance overthinking and impulse decision. No more analysis paralysis if you apply the 37% rule. You can see how the algorithm could be applied to other situations in real life:\n\nHow much time should you spend circling a parking lot before committing to a spot in the hope that a better spot opens up?\nHow many offers should you reject before selling the car or house in the hope to get a better offer?\nHow long should you be dating before finding the “optimal” partner?\n\nThe 37% rule is not optimal in all decision problems. Situations where the rule applies are characterized by the following:\n\nYou have to choose a singleton (one apartment, one parking spot, one partner).\nThere are \\(n\\) possible choices and \\(n\\) is known.\nIt is possible to rank all \\(n\\) choices from best to worst.\nThe choices appear sequentially in a random order.\nAfter meeting a choice, a decision is made immediately to reject or accept it.\nA choice cannot be revisited after rejection or acceptance.\nIf you come to the final (\\(n\\)th) choice you have to take it.\n\nThe optimum achieved by the 37% rule is to maximize the probability to select the best choice among the \\(n\\) possibilities. The rule does not guarantee that the best choice is made. But no other rule has a higher probability of finding the best choice under the circumstances.\n\nThe Secretary Problem\nThe optimal stopping problem is also known as the secretary problem, the sultan’s dowry problem, the fussy suitor problem or the marriage problem. In terms of hiring a secretary, it goes as follows.\nYou want to hire the best secretary out of \\(n\\) applicants for a position. Applicants are interviewed in a random order one by one. After the interview you decide whether to accept or reject the candidate. If you reject an applicant they take another job and cannot be reconsidered. While interviewing the applicant you gather information that allows you to rank the candidate against those interviewed so far but you do not know the quality of the yet to-be-interviewed candidates.\nThe 37% rule states that you should be evaluating the first 37% applicants to create a ranking. That completes the looking phase. Then leap and make an offer to the next applicant that ranks higher than the best applicant interviewed during the looking phase.\nBut wait, what if there is only one applicant? Or two?\nWith a single applicant you need to hire them, and you are guaranteed to have hired the best of the (single) bunch. With two applicants, if you pass on the first, you have to hire the second. In this case you can flip a coin, either hire the first or pass and be forced to hire the second—you cannot do better than chance. With \\(n=3\\) candidates the optimal rule is to look at the first candidate, then choose the second candidate if they beat the first. This is a 1/3 x 100% = 33.3% rule and has a 50% probability of finding the best candidate.\nAs \\(n\\) increases, the optimal rule approaches \\(1/e \\times 100\\% = 36.8\\%\\) and that is also the probability of finding the best candidate. Round that percentage up and you see why it is called the 37% rule.\nYou might say that a 37% chance of making the best choice is not very good. In 63% of all cases we are not finding the best candidate. The result is not that bad if you compare it against a pure random chance. If there are 100 candidates for the position, then a random choice has a 1% chance of getting the best candidate. In a pool of 1,000 candidates, random selection has a 0.1% chance of locating the best. However, the odds of finding the best candidate under the optimal stopping rule does not change. The more choices you have, the better optimal stopping performs relative to random selection. But even with only three candidates the likelihood of finding the best candidate has improved from 1 out of 3 to 1 out of 2.\n\n\nIssues with the Optimal Stopping Rule\nBut wait, you say. Pure random selection is not the appropriate benchmark against which to compare the optimal stopping rule. This is not how we hire people in the real world. In other words, the situation where the 37% rule applies does not describe how we do things.\nWhat are some of the ways in which the optimal stopping setup is unrealistic:\n\nWe often do not know \\(n\\), the number of choices. For example, we might not know how many apartments in San Francisco are on the market. There is a workaround: if \\(n\\) is unknown, we can base the 37% rule on a time interval: we give ourselves one month to find an apartment and enter the leap phase after 10 or 11 days.\nThe choices do not come to us in a random order. In an interview process there are short lists and candidates are screened and filtered. The order in which candidates come to the interview is not completely at random.\nAfter rejecting a candidate, we do have the option to go back. If it turns out that none of the other candidates was better than a candidate rejected earlier, then we can go back and reconsider the choice. After rejecting a date, we can ask them on another date—theoretically.\nIn real life, we are not making decisions after seeing a candidate. Instead, applicants are grouped (pre-screening, initial phone interview, on-site interview, …) and choices are made after each batch of candidates.\nThe optimal stopping problem assumes that we do not have a ranking of the candidates. It only assumes that there is an objective method of ranking them and that we rank as we go. Obviously, candidates are evaluated based on many criteria and these are known ahead of time. The look phase of the optimal stopping exists because it is needed to calibrate what good candidates look like. We know this a priori of time, and we can evaluate candidates (somewhat) based on their resumes.\nWe do not only have a sense of which candidate ranks higher or lower, but also by how much. Meeting a candidate that really stands out changes the likelihood of making a decision. If you know that a candidate is in the top 10% of SAT or GRE scores, there is only a 1 in 10 chance that others will be better.\nThe job will be offered to a candidate in the leap phase, not the looking phase. The Human Resources and the Legal departments are probably going to have a conniption if the first 37% of candidates being interviewed have no chance of getting the job. Queue the lawsuits. Your dates might not respond kindly when they find out that you are “just looking”.\n\n\nThe optimal stopping scenario and the 37% rule are useful to construct a mental model of how to go about a decision that involves sequentially evaluating choices and deciding on a particular choice. As with any model, we have to examine the assumptions and conditions under which the model applies. We quickly see that the assumptions do not map cleanly to real-life situations such as hiring, finding a partner, or even circling a parking lot for the best empty space.\nAs G.E.P. Box said\n\nAll models are wrong. Some are useful.\n\nThe utility of casting real-life decision situations in terms of an optimal stopping problem lies in understanding that under special circumstances there is an optimal way to balance impulse and procrastination and to realize in what ways our decision situation deviates from that scenario. Are we in a no-information scenario as in the classical secretary problem where we have no a-priori data about the quality of the applicants or are we in a full-information scenario where the quality of all applicants can be quantified a priori? If it is the latter we should come to a decision more quickly than going through at least 37% of the stack.\nA situation where the algorithm applies cleanly to a real-life situation is when we are placing things in order—the task of sorting. The question then is what is the most efficient way to go about it?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algorithms to Live By</span>"
    ]
  },
  {
    "objectID": "life_algorithms.html#searching-and-sortinga-tradeoff",
    "href": "life_algorithms.html#searching-and-sortinga-tradeoff",
    "title": "8  Algorithms to Live By",
    "section": "8.3 Searching and Sorting—A Tradeoff",
    "text": "8.3 Searching and Sorting—A Tradeoff\nSearching means finding things in a collection. Sorting means arranging a collection in order. Both are fundamental tasks in data processing. Sorting was one of the first applications for computers, making sense of the 1890 census. Tallying the previous census by hand took 8 years, just enough to finish the task before the next census (Christian and Griffiths 2017). With growing number of questions asked on every census, something needed to be done, the 1890 census would not be tallied by hand in time for the 1900 census. Enter the Tabulator, a punchcard-based machine invented by Herman Hollerith and adapted for the 1890 census (Figure 8.1).\n\n\n\n\n\n\nFigure 8.1: Tabulator with sorting machine invented by Herman Hollerith. Source: Wikipedia\n\n\n\nSorting was one of the most important tasks for computers. Christian and Griffiths (2017) state\n\nBy the 1960s, one study estimated that more than a quarter of the computing resources of the world were being spent on sorting.\n\nand it is still at the heart of many algorithms. Every time you see a ranking, a largest or smallest value, a 95th percentile, a leader board or a top-10, a list had to be arranged by value, sorted at least partially.\nAs an exercise, can you think of some ways in which you encounter sorted things every day? Here is a start:\n\nSports teams are ranked by criteria such as number of wins and losses, and displayed from highest to lowest.\nMusic is ranked by popularity, measured as number of downloads, sales, etc.\nMusic is grouped (sorted) by genre.\nStreaming services recommend things to watch according to an algorithm that ranks shows based on your watch history.\nDisplays of countries are sorted by all kinds of attributes. The medal count in the Olympic Games, gross domestic product (GDP), annual oil production, emissions, etc.\nA Google search returns the search results sorted according to relevance. The relevance is determined through a number of factors such as Google’s famed PageRank algorithm, which sites are sponsored, and so forth. Without sorting the search results you would have to sift through millions of links to determine which ones are most relevant to your search. The ranking is very effective, less than 1% of Google searches scroll to the second page.\nThe email Inbox is sorted by some criteria, read/unread, message thread, time of arrival, etc.\nOn computers, files and folders can be arranged by attributes such as size, time of creation, time of modification, name, etc.\nThe U.S. Postal Service sorts mail by zip code.\nSocial media sites create personalized feeds based on sorting contributions according to their algorithms.\nSearching for items in an online store you can arrange the results by brand, price, popularity, etc.\nBooks in the library are organized into buckets by call numbers and are sorted alphabetically within buckets.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algorithms to Live By</span>"
    ]
  },
  {
    "objectID": "life_algorithms.html#asymmetric-cryptography",
    "href": "life_algorithms.html#asymmetric-cryptography",
    "title": "8  Algorithms to Live By",
    "section": "8.4 Asymmetric Cryptography",
    "text": "8.4 Asymmetric Cryptography\n\nConsider the following scenario.\nBob and Alice are pen pals and are sending letters to each other by snail mail. At one point, Bob wants to send Alice a package that contains a valuable item. Unfortunately, thieves have been breaking open packages and stolen the contents. To prevent that from happening, Bob places the item inside a box and places a lock on it. The problem now is, how can Alice open the lock without having the key to it? One option is for Bob to communicate the lock combination by some other means to Alice. If it is a keyed lock, he could send the key to her in another mailing. In any event, he does not want to include the key in the package itself, that would be pointless. And sending the combination or key separately still comes with risks. The information could be intercepted and when a thief gets their hands on the package with the valuable item they could steal it.\nHow can Bob send the item safely to Alice and she is guaranteed to receive it without exchanging information about the lock itself?\nThe solution lies in asymmetric cryptography, also called asymmetric encryption. Prior to the invention of asymmetric encryption secrets were sent around that enable recipients to decrypt messages. The obvious problem of symmetric encryption is that if someone gets hold of message and decryption key, they can decipher the message. Everything hinges on keeping the keys safe.\nHow could Bob and Alice handle the situation without exchanging secrets (keys) about the box? It involves two keys. When Bob sends the package to Alice, he attaches his lock to the box. Upon receipt, Alice attaches her lock as well and sends the package back to Bob. He recognizes the package came from Alice and removes his lock, then sends it back to Alice.\nAlice now receives the box that contains the valuable item protected with her own lock. She uses her own key to open it and retrieves the item.\nOnly the owners of the keys used it to lock and unlock the box. The keys were never exchanged. This came at the expense of sending the package back and forth a few times. This could be optimized in the following way: suppose we use a special (single) lock with two keys: a key anyone can use to lock it, but a key unique to Alice to unlock it. Alice shares the first key with anyone who sends her packages and keeps the key to unlock a secret (shares it with no one). When Bob sends a package to Alice, he locks the box with her public key. When he sends a package to Fred, he secures it with his public key.\nThis is essentially how most messages traveling over the internet are secured, based on a pair of related keys.\n\n\n\nFigure 8.1: Tabulator with sorting machine invented by Herman Hollerith. Source: Wikipedia\n\n\n\nChristian, Brian, and Tom Griffiths. 2017. Algorithms to Live by. The Computer Science of Human Decisions. Henry Holt; Company, New York.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Algorithms to Live By</span>"
    ]
  },
  {
    "objectID": "genAI.html",
    "href": "genAI.html",
    "title": "9  Generative AI",
    "section": "",
    "text": "9.1 A Brief History of AI\nArtificial Intelligence (AI) is in every conversation. Everywhere you turn you hear “AI this”, “AI that”, and too many people are now pretending to be AI experts. This has not always been the case. Some decades ago, when you’d tell anyone you work in artificial intelligence they would not take you serious. If you’d try to get a research grant better not mention the term artificial intelligence. This was the time of the AI winter that followed a period of overblown expectations and hyped predictions what machines would be capable of doing.\nPeriods of AI hype (AI summers) and AI disappointment (AI winters) are cyclic, currently we are in another AI summer since the arrival of capable foundation models and GPT-style technology. Once more you hear voices claiming machines have/are becoming sentient and that the era of artificial general intelligence, when machines can think for themselves, is just around the corner.\nDo we know more about AI then back then? Are we better at predicting the future of technology now than we were back then?\nArtificial intelligence (AI) refers to building systems that can perform tasks or make decisions that a human can make. The systems are built on various technologies, mechanization, robotics, software engineering, among them. Many AI systems today are entirely software based, large language models (ChatGPT, Gemini, Claude Sonnet) for text processing or diffusion-based systems for image generation are examples.\nFigure 9.1 shows an example of a mechanized AI system, called the Mechanical Turk. It was an automaton, a device made to imitate an human action. The action in this case was to play chess.\nYou can imagine that building a purely analog machine that plays chess is difficult. To accomplish this in the 18th century is quite remarkable. It was not possible. The Mechanical Turk was a hoax. The cabinet concealed an human player who operated the chess pieces from below the board.\nPerforming human tasks by non-human means is as old as humanity. Goals are increased productivity through automation, greater efficiency and strength, elimination of mundane, boring, or risky tasks, increasing safety, etc.\nThe two major AI winters occurred during the periods 1974–1980 and 1987–2000. One was triggered by disappointment with progress in natural language processing, in particular machine translation. The other was triggered by disappointment with expert systems.\nDuring the Cold War the government was interested in the automatic, instant translation of documents from Russian to English. Neural network architectures were proposed to solve the task. Today, neural network-based algorithms can perform language translation very well, it is just one of the many text analytics task that is done well by AI today. In the 1950s and 60s progress was hindered by a number of factors:\nThe expectations for the effort were sky high, however. Computers were described as “bilingual” and predictions were made that within the next 20 years essentially all human tasks could be done by machines.\nAn expert system is a computerized system that solves a problem by reasoning through a body of knowledge (called the knowledge base), akin to an expert who uses their insight to find answers based on their expertise. Expert systems were an attempt to create software that “thinks” like a human. The problem is that computers are excellent at processing logic, but not at reasoning. The reasoning system, called the inference engine, consisted mainly of rules and conditional (if-else) logic. We are still using expert systems today, but a very special kind, those that can operate with captured logic rather than having to reason. Tax software is an example of such an handcrafted knowledge system—a very successful one at that. Most taxpayers would not think twice to use software such as TurboTax or TaxSlayer to prepare their income tax return.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generative AI</span>"
    ]
  },
  {
    "objectID": "genAI.html#a-brief-history-of-ai",
    "href": "genAI.html#a-brief-history-of-ai",
    "title": "9  Generative AI",
    "section": "",
    "text": "Figure 9.1: Mechanical Turk, a chess-playing automaton in the 18th century.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCynics might say that 2 1/2 centuries removed, we are still operating by the same principle. When you ask a large language model to write a poem in the style of Edgar Allan Poe, the poet behind the curtain is represented by the volumes of literature used to train the language model so that it can respond in the requested style.\n\n\n\n\n\n\nlack of computing power to build large, in particular, deep networks\nlack of large data sets to train the networks well\nneural networks specifically designed for text data had not been developed\n\n\n\n\nEasy for Computers, Easy for Humans\nTax software works well and is a successful AI effort because it performs a task that is easy for computers but intellectually difficult for humans. The tax code is essentially a big decision tree with many branches and conditions. That is easy to convert into machine instructions–there is no reasoning. If the adjusted gross income is $X, and the deductions are $Y, and the payer is filing jointly with their spouse, …, then the tax is this amount. It is difficult for us to memorize the entire logic and execute it without errors.\nAn expert system that performs logic reasoning is the exact opposite: it performs a task that is easy for us but very difficult to perform for a computer. Imagine to create an expert system that can operate a car by converting how a human operator drives a car into machine instructions. We instantly recognize an object in the road as a deer and plan an evasive action. A machine would need to be taught how to recognize a deer in the first place.\nHumans excel solving problems that require a large amount of context and knowledge about the world. We look at a photo or glance out the window and instantly see what is happening. Seeing, sensing, speaking, operating machinery are such problems. Unlike the tax code, they are very difficult to describe formally.\nThe revolution in artificial intelligence since the mid 2000s, what one could call the AI spring to the ChatGPT AI summer we are in, launched when our ability to solve problems that require knowledge about the world increased by orders of magnitude. The key was a new discipline, deep learning, which turned out to be a renaissance of decade-old ideas.\n\n\nNeural Networks–Again",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generative AI</span>"
    ]
  },
  {
    "objectID": "genAI.html#what-is-generative-ai",
    "href": "genAI.html#what-is-generative-ai",
    "title": "9  Generative AI",
    "section": "9.2 What is Generative AI?",
    "text": "9.2 What is Generative AI?\nGenerative Artificial Intelligence (GenAI) refers to artificial intelligence systems that are not explicitly programmed and are capable of producing novel content or data. For example, a genAI system might be prompted with some text to produce new text or it might generate an image based on your description of the content and style of the image.\nThe underlying technology of a GenAI system can be a generative adversarial network (GAN), a variational autoencoder (VAE), a diffusion-based system for image generation, or a generative pre-trained transformer (GPT). Whatever the technology, GenAI systems have some common traits that are relevant for our discussion.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generative AI</span>"
    ]
  },
  {
    "objectID": "genAI.html#ethical-considerations",
    "href": "genAI.html#ethical-considerations",
    "title": "9  Generative AI",
    "section": "9.3 Ethical Considerations",
    "text": "9.3 Ethical Considerations\n\nHarm\n\n\nBias\n\n\nHallucinations\n\n\nIntellectual Property Rights\n\n\nPrivacy",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generative AI</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Adhikari, Ani, John DeNero, and David Wagner. 2022. Computational\nand Inferential Thinking: The Foundations of Data Science. 2nd Ed.\nhttps://inferentialthinking.com/chapters/intro.html.\n\n\nAndreessen, Mark. 2011. “Why Software Is Eating the World.”\nhttps://a16z.com/why-software-is-eating-the-world/.\n\n\nBox, George E. P. 1976. “Science and Statistics.”\nJournal of the American Statistical Association 71 (356):\n791–99.\n\n\nBox, George E. P., and Norman R. Draper. 1987. Empirical\nModel-Building and Response Surfaces. John Wiley & Sons, New\nYork.\n\n\nChristian, Brian, and Tom Griffiths. 2017. Algorithms to Live by.\nThe Computer Science of Human Decisions. Henry Holt; Company, New\nYork.\n\n\nHuff, Darrell. 1954. How to Lie with Statistics. W.W. Norton\n& Company, New York.\n\n\nMesserli, F. H. 2012. “Chocolate Consumption, Cognitive Function,\nand Nobel Laureates.” New England Journal of Medicine\n367: 1562–64.\n\n\nNeyman, Jerzy. 1952. Lectures and Conferences on Mathematical\nStatistics and Probability. Graduate School, Dept. of Agriculture,\nWashington.\n\n\nSilver, Nate. 2012. The Signal and the Noise: Why so Many\nPredictions Fail–but Some Don’t. Penguin Books.\n\n\nSnow, John. 1855. On the Mode of Communication of Cholera, 2nd.\nEd. John Churchill, London. https://archive.org/stream/b28985266#page/n3/mode/2up.\n\n\nTent, M. B. W. 2006. The Prince of Mathematics: Carl Friedrich\nGauss. CRC Press, Boca Raton, FL.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Big-O notation\nHow computer scientists measure algorithm complexity. It does not express how long an algorithm takes to run, but how its runtime depends on the size of the problem.\nAlgorithms and our Lives * “Weapons of math destruction” according to Cathy O’Neill. Characteristics of WMD are scale, impact, feedback loop * Gaming the system by focusing/manipulating on metrics which are surrogates for the difficult-to-quantify * Examples from the book * Digital advertising * College rankings * Evaluating job candidates * Sentencing * Financial markets * Credit scoring * Bias and Harm in Algorithnms * Types of biases * Question: what does the rise of generative AI mean for WMDs and bias/harm from algorithms\nCausality and Association * The difference between correlation and causation * John Snow and the 1854 Cholera outbreak in Soho, London * https://en.wikipedia.org/wiki/1854_Broad_Street_cholera_outbreak * https://inferentialthinking.com/chapters/02/1/observation-and-visualization-john-snow-and-the-broad-street-pump.html * Towards causation: comparing groups of people * https://inferentialthinking.com/chapters/02/2/snow-s-grand-experiment.html * Observational and experimental data * Randomization\nDataism\nR & RStudio * Decision trees in R with rpart and rpart.plot packages *\nApplications\nBooks\nSurrogacy—Gaming the metric Plenty of examples in Cathy O’Neil’s book, for example, college rankings by US News & World Report, using proxies for academic success such as graduation rates.",
    "crumbs": [
      "Notes"
    ]
  },
  {
    "objectID": "notes.html#big-o-notation",
    "href": "notes.html#big-o-notation",
    "title": "Notes",
    "section": "",
    "text": "\\(O(1)\\): Constant time. Runtime is the same regardless of problem size. Cleaning the kitchen before a dinner party takes the same amount of time, whether you eat by yourself or invite 5 guests or 20 guests. Cleaning the house can depend on the number of guests, if you have to clean areas of the house for larger groups that you would not have to clean for small groups. In that case, cleaning would not be a O(1) operation.\n\\(O(n)\\): Linear time. The time to pass the roast around the dinner table. Twice the number of guests and you have to wait twice along for the dish to come around.\n\\(O(n^2)\\): Quadratic time. The runtime grows quadratically with the problem size. What matters are the contours of the relationship between size and time, not whether it is \\(n^&2\\) or \\(3n^2\\)—it is all \\(O(n^2)\\). Quadratic time would apply if each guests hugs all others as they arrive, The first guest would hug only the host, the second guest would give two hugs, the the third guest hugs three, and so on. In total, with \\(k\\) guests, there will be \\(k(k+1)/2\\) hugs. Because the term of highest order is quadratic, the algorithm is \\(O(n^2)\\). (Note that this formula is an application of Gauss’ trick to find the sum of the first 100 numbers by recognizing that there are 50 terms with a partial sum of 101.)\n\n\n\n\n\n\n\nDoes icing the kicker in the NFL work? From Chance magazine: https://chance.amstat.org/2024/10/icing-the-kicker/\n\n\n\nCathy O’Neil: Weapons of Math Destruction: https://research-ebsco-com.ezproxy.lib.vt.edu/linkprocessor/plink?id=5b2ef1a8-858c-3aa5-b0cd-d3f8932fadce\nDavid Spiegelhalter: The Art of Statistics\nNate Silver: Signal and Noise",
    "crumbs": [
      "Notes"
    ]
  }
]