

# Data Literacy {#sec-literacy}

Data literacy is the ability to understand, interpret, critically evaluate, and 
effectively communicate data in context. It is not a technical skill but a fundamental 
capability for everyone. Can you explain what these statements mean?

* The chance of rain tomorrow is 30%.
* The estimated total number of trees on earth is 3.04 trillion with a margin of error of 0.1 trillion.
* The median income in the US in 2022 was $37,585.
* The drug shows a significant number of adverse side effects.
* The cancer screening test has a false positive rate of 12\%.

Key skills of the data literate person are to 

- Understand and critique conclusions based on data
- Assess the trustworthiness of claims based on data (processing)
- Transform raw data into insights

This module covers a number of concepts and topics around data and data analysis
that help you become more data literate.

## Uncertainty

## Signal and Noise {#sec-literacy-signal-noise}

Separating the signal from the noise is a key objective in all data analysis.
The **signal** represents the systematic, non-random effects in the data. Data scientists
and statisticians define the **noise** as the unpredictable randomness around the signal. 
A slightly different, and also useful, definition of noise stems from intelligence
analysis. The signal is the information we are trying to find, the noise is the 
cacophony of other information that obscures the signal. That information might 
well be a signal for something else but it is irrelevant or useless for the 
event the intelligence analyst is trying to predict. 

Information not being relevant for the signal we are trying to find is the key.
In the view of the statistician, that information is due to random events.

Finding the signal is not trivial, different analysts can arrive at different
models to capture it. Signals can be obscured by noise. What appears to be a 
signal might just be random noise that we mistake for a systematic effect. 

:::{.example}
::::{.example-header}
Example: Theophylline Concentration
::::

::::{.example-container}
@fig-theop-data shows the concentration of the drug theophylline over 24 hours
after administration of the drug in two groups of patients. 
There are 98 data points of theophylline concentration and
measurement time. What are the signals in the data? What is noise?

```{r, include=FALSE}
theop  <- read.csv("data/theophylline.csv")
attach(theop)
```

```{r, echo=FALSE, fig.align="center", out.width="90%"}
#| label: fig-theop-data
#| fig.cap: Theophylline concentration over time in two groups of patients.
plot(time,conc, 
     ylab="Concentration",
     xlab="Time (hrs)",
     pch=group, 
     col=group,cex=0.8, las=1,bty="l")
gr <- unique(theop$group)
legend("topright",
       legend=c("Group 1","Group 2"),
       cex=0.8,
       pch=gr,col=gr)
```


The first observation is that the data points are not all the same over time, 
otherwise they would fall on a horizontal straight line: there is **variability**
in the data. Separating signal and noise means attributing this variability to 
different sources: some systematic, some random.

Focusing on either the open circles (group 1) or the triangles (group 2), you 
notice that points that are close in time are not necessarily close in the 
concentration measurement. Not all patients were measured at exactly the same 
time points, but at very similar time points. For example, concentrations were
measured after about 7, 9, and 12 hours. The differences in the concentration
measurements among the patients receiving the same dosage might be due to 
patient-to-patient variability or measurement error. 

Focusing on the general patterns of open circles and triangles, it seems that 
the triangles appear on average below the average circle a few hours after 
administration. Absorption and elimination of theophylline appears to behave 
differently in the two groups.

Much of the variability in the data seems to be a function of time. Shortly after
administering the drug the concentration rises, reaches a maximum level and then
declines as the drug is eliminated from the body. Note that this sentence describes
a general overall trend in the data here. 

Which of these sources of variability are systematic---the signals in the data---
and which are random noise?

- Patient-to-patient variability within a group at the same time of measurement: 
we attribute this to random differences among the participants.

- Possible measurement errors in determining the concentrations: random noise

- Overall trend of drug concentration over time: signal

- Differences among the groups: signal

These assignments to signal and noise can be argued. For example, we might want 
to test the very hypothesis that there are no group-to-group differences. If that
hypothesis is true, any differences between the groups we discern in @fig-theop-data
would be due to chance; random noise in other words.

The variability between patients could be due to factors such as age, gender, 
medical condition, etc. We do not have any data about these attributes. By 
treating these influences as noise, we are making important assumptions that
their effects are irrelevant for conclusions derived from the data. Suppose that
the groups refer to smokers and non-smokers but also that group 1 consists of
mostly men and group 2 consists of mostly women. If we find differences in 
theophylline concentration over time among the groups, we could not attribute those
to either smoking status or gender.
::::
:::

A common reason to mistake signal for noise is **overfitting** a model, a concept 
we return to in @sec-literacy-overfitting.

Another reason is if there is simply no signal at all. @fig-random-walk is
taken from @Silver2012 [p. 341] and displays six "trends". Four of them are 
simple random walks, the result of pure randomness. Two panels show the movement
of the Dow Jones Industrial Average (DJIA) during the first 1,000 trading days of the
1970s and 1980s. Which of the panels are showing the DJIA and which are random
noise?


![Figure 11-4 from @Silver2012, Random walk or stock market?](images/Figure11_4_Silver.png){#fig-random-walk fig-align="center" width=80%}

What do we learn from this?

- Even purely random data can appear non-random over shorter sequences. We can
easily fall into the trap of seeing a pattern (a signal) where there is none.
After drawing two unlikely poker hands in a row there is not a greater chance
of a third unlikely hand unless there is some systematic effect (cards not 
properly shuffled, game rigged). Our brains ignore that fact and believe that 
we are more lucky than is expected by chance.

- Data that contains clear long-run signals---the stock market value is increasing
over time---can appear quite random on shorter sequences. One a day to day basis
predicting whether the market goes up or down is very difficult. In the long run
ups and downs are almost equally likely. Upswings have a slight upper hand and 
on average are greater than the downswings, increasing the overall value in the
long term. Traders who try to beat the market over the short run have their work
cut out for them.

By the way, panels D and F in @fig-random-walk are from actual stock market data.
Panels A, B, C, and E are pure random walks. It would not be surprising if 
investors would bet money on "trend" C.


## Accuracy and Precision {#sec-literacy-accuracy-precision}

The terms **accuracy** and **precision** are often used interchangeably. In the 
context of measurement and data analysis they mean different things and the 
distinction is important.

When talking about measuring devices, accuracy and precision are defined as

-   **Accuracy**: How close are measurements to the true value
-   **Precision**: How close are measurements to each other

When folks say that something is precise, what they often mean is that it is
accurate. For example, when you measure something that is 8 feet long with a tape
measure and the tape reads 8 feet, then it is accurate. If you repeat the measurement
several times and all readings are close to 8 feet, then the tape (and you as its
operator) is precise.

Precision refers to the repeatability of a method, accuracy refers to its 
proximity to a target value.

To demonstrate the difference between accuracy and precision, the dart board 
bullseye metaphor is helpful. @fig-dartboard shows four scenarios of shooting four 
darts each at a dart board. Suppose we are trying to hit the bullseye in the 
center of the board; it is the true value we are trying to measure. 

* Pattern **A** is the result of a thrower who is neither accurate nor precise. The throws 
vary greatly from each other (lack of precision), and the average location is 
far from the bullseye (inaccurate). 

* Pattern **B** is the result of a thrower who is inaccurate but precise. The throws group 
tightly together (high precision) but the average location misses the bullseye 
(the average distance from the bullseye is not zero). 

* Pattern **C** is typical for a player who is not precise, but accurate. The 
throws vary widely (lack of precision) but the average distance of the darts from 
the bullseye is close to zero---on average the thrower hits the bullseye. 

* Pattern **D** is that of an accurate and precise player; the darts group tightly 
together and are centered around the bullseye.

![Accuracy and precision---the dart board bullseye metaphor.](images/Bullseye.png){#fig-dartboard .lightbox fig-align="center"}

Another way to phrase accuracy and precision are in terms of the distribution of
the measurements. Accuracy is about the average (central tendency) of the values, 
precision is about their variability. A statistical method that is not accurate---does
not hit the target on average---is said to be **biased**.

---

Why do we worry about the distinction of precision and accuracy? 

If we have a choice among different methods of drawing conclusions from data, 
we would opt for the one that is most precise and most accurate. To decide 
whether to buy, hold, or sell stock of company X, it would be great if we can
forecast the stock value accurately and precisely. Imagine that you are the coach
of the dart team. It is the end of the tournament, your team has one last dart
left to throw; the team that gets closest to the bullseye will win the tournament. 
Which of the four types of players would you ask to make the throw? The precise 
and accurate player **D**  is the safe bet. 

Unfortunately, we often do not have the luxury of a uniformly optimal method that
has no bias and highest precision among all methods. We often need to make a
compromise, and that means we have to weigh precision and accuracy against each
other. 

Statisticians historically resolve the tension by demanding that methods are 
accurate (have zero statistical bias). Among all competing methods in that collection
they then choose the one that has the highest precision (smallest variance). That
is a reasonable approach especially if accuracy is most important.

However, it is possible that the most precise unbiased method is much more
variable than a biased method. In the dartboard example, if player **D** has
retired from the sport, then we might bet on player **B** for the last throw. She
has a higher likelihood of getting close to the bullseye than the more erratic---but
close on average---player **C**.

We also worry about the distinction between accuracy and precision because our
confidence in statements about data should include both. The precision of a 
method translates into uncertainty about its results. An imprecise method leads
to uncertain conclusions. Pundits who offer ostensibly expert opinions about topics 
frequently provide predictions without telling us how precise they are:

- "Candidate A is ahead of candidate B by three points."
- "Inflation will decrease by half a point in the next quarter."
- "60\% of adults between 35 and 45 support this legislation."
- "The average temperature on the planet will increase by 1.4 degrees centigrade
by 2030".

These statements let us tacitly assume that the prediction is accurate and infinitely 
precise. If accompanied by a measure of precision---that is, uncertainty---the 
message is much more nuanced:

>"Candidate A is ahead of candidate B by three points. The margin of error is +/- 5 points". 

The margin of error covers the possibility that candidate B is in the lead. 

>"The average temperature on the planet will increase by 1.4 degrees centigrade by 2030".
The 95\% prediction interval in 2030 ranges from 0.2 to 2.6 degrees.


## Causation and Correlation {#sec-literacy-correlation}

You might have heard the saying "correlation is not causation." What is meant by
that? 

Causation implies that one thing is the result of another thing; they 
stand in a cause-and-effect relationship to each other. The gravitational pull
of the moon on earth's oceans causes the tides. An accident causes a traffic jam.
Smoking causes an increase in the risk of developing lung cancer.

Correlation, on the other hand, is about establishing **association** between 
attributes. The weight of a person is correlated with their height. Taller 
people tend to be heavier but height alone is not the only factor affecting 
someone's weight. Smoking is correlated with alcoholism but does not cause it.

In @sec-cholera we discussed the 1854 cholera outbreak in Soho, London and 
John Snow's investigation. He found higher cholera incidences in houses closer
to the Broad Street public water pump. There was at least an association between
cholera cases and proximity to the pump. Did the pump---or more precisely the
water from the pump or something in the water---cause cholera? Today we know that
cholera is caused by the bacterium *Vibrio cholerae*, but that discovery was not
made until 1883. 

We experience correlation when one attribute changes with another.
@fig-correlations shows various patterns in which two continuous attributes
might be correlated. When the correlation is positive, one attribute tends to
increase as the other increases. If the correlation is negative, an increase
in one attribute is associated with a decrease in the other attribute.

![Correlations of different strength and directions. The numbers above the point clouds indicate the strength and direction of the correlation](images/different_correlations.png){#fig-correlations fig-align="center" width=85%}

Correlations are measured by the correlation coefficient, which ranges from -1
to 1. These extremes are called perfect correlations and happen when all points
fall on a perfect line, without variability about the line. 

It seems obvious that just because two attributes vary with each other---are
correlated---one should not infer that they are cause and effect of each other.
Unfortunately, that leap of faith is often made and can lead to very problematic
decisions.

![Chocolate consumption and number of Nobel laureates.](images/Chocolate.png){#fig-chocolate-corr fig-align="center" width=75% .lightbox}

@fig-chocolate-corr displays the number of Nobel laureates per 10 million population
against the chocolate consumption (in kg per capita and year) for various countries
[@Messerli_2012].
An upward trend is clearly noticeable. A greater per-capita chocolate consumption
is associated with a lager number of Nobel laureates. Whoa! If the two variables
stand in a cause-effect relationship then we have a simple recipe to increase
Nobel prizes: we all should eat more chocolate. While one can argue the benefits 
of chocolate for cognitive function, what we have here is a simple correlation. 
The two attributes, number of Nobel laureates per 10 million population and chocolate 
consumption per capita, are related. If one increases so does the other. But why?

This is an example of a **spurious** correlation. The variables are not really
dependent on each other, a relationship is induced in some other way. In this 
particular example, the correlation was "found" by cherry-picking the data:
only four years of chocolate consumption were considered on a limited number of 
chocolate products and no data prior to 2002 was used. The number of Nobel 
laureates is a cumulative measure that spans a much longer time frame.

It appears that the data were organized in such a way as to suggest a relationship 
between the variables. 

You can find spurious correlations everywhere, without manipulating the data.
Here are some examples and the reasons why the data appear correlated.

### Examples of Spurious Correlations

#### Coincidence

Forecasting economic conditions is difficult and highly valuable. Since the end
of World War II there have been only eleven economic recessions. On the other 
hand we are producing thousands of economic indicators. The government alone 
generates 45,000 economic statistics each year [@Silver2012, p.185].

So it should not be surprising that when sifting through all those variables we
find some that appear to go up or down together, just by coincidence.

A famous example is the Super Bowl winning conference as an indicator of economic
performance. Between 1967 and 1997, in years when the team from the original NFL 
won, the stock market went up by 14\%. When a team from the original AFL won the 
stock market decreased by almost 10\%. Through 1997, the Super Bowl winner "predicted"
correctly the direction of the stock market in 28 out of 31 years [@Silver2012].
Since 1998 the trend has reversed and the stock market is doing better when an 
AFL team won the Super Bowl. Coincidence during a period of time leads to mistake
noise for signal.

Another example of coincidence being mistaken for correlation is 
[Paul, the octopus](https://en.wikipedia.org/wiki/Paul_the_Octopus) who correctly
predicted the winner in 2008--2010 international soccer matches 12 out of 14 times,
an 85\% accuracy. Since this success rate is unlikely to happen by chance, it was
determined that Paul the octopus has divine powers. When Paul got it wrong in 
a 2010 FIFA World Cup game between Germany and Spain, the German fans called for
Paul to be eaten and the Spanish Prime Minister offered Paul asylum.

#### Latent variables

A correlation between variables A and C can be induced by another variable, say B.
If A is correlated with (or caused by) B and C is correlated (or caused by) B,
then plotting A versus C indicates a correlation between the two variables.
However, the relationship is induced by the **latent variable** B.

![Spurious correlation.](images/spurious3.jpg){#fig-spurious-corr fig-align="center" width=65%}

Latent variables are often the real reason why things appear related when we
deal with variables that depend on population size or common factors 
such as the weather or time. @fig-spurious-corr shows the close relationship over
time between the number of high school graduates and donut consumption. More 
donut consumption appears related to more high school graduates. Notice that
we are not plotting graduation **rates**, these would most likely not have any
relationships with donut consumption. The latent variable at work in @fig-spurious-corr
is the size of the population over time. As the population increases, more donuts
are consumed and more people graduate from high school.

A similar spurious correlation is that between ice cream sales and forest fires.
Both increase during the summer heat and decrease in the winter.

You can imagine the horrible public policy decisions one would make by mistaken
those spurious correlations for cause and effect.

#### Induced correlation

Another interesting mechanism to induce correlation is by introducing a 
mathematical dependence between two attributes. A famous example is the relationship
between birth rate and the density of storks.

![Storks and Babies](images/Stork.png){#fig-stork-baby fig-align="center" width=45%}

In central Europe a persistent myth is that storks bring babies. [Movies](https://en.wikipedia.org/wiki/Storks_(film))
were made about it! The origin of the association probably goes back to medieval 
days when conception was more common in mid-summer during the celebration of the 
summer solstice which is also a pagan holiday of marriage and fertility. The 
white stork is a migratory bird that flies to Africa in the fall and returns to 
Europe nine months later. Hence the connection was made that storks brought
the babies.

Although the myth has been debunked, there have been several studies of the connection 
between fertility and the stork abundance. @Neyman_1952 describes a study of 54 
counties that comprises the following attributes

- $W$: Number of women of child-bearing age in the county (in 10,000)
- $S$: Number of storks in the county
- $B$: Number of babies born in the county

Since it is likely that these numbers increase with the size of the county, the 
variables analyzed were $Y = B/W$ and $X=S/W$, the birth rate per 10,000 women 
and the density of storks per 10,000 women. A plot of these variables and a
smooth estimate of their trend is shown in @fig-stork-trend. 
 
![Storks and babies.](images/Storks_and_Babies.png){#fig-stork-trend fig-align="center" width=75%}

It certainly appears that the birth rate increases with the density of storks.
Could the myth be true? Is something else going on?

The trend in @fig-stork-trend is induced by expressing both variables as ratios
with the same variable, $W$, the number of women of child-bearing age. If
$S$ and $B$ are unrelated, $S/W$ and $B/W$ now share information because they
are expressed relative to another variable.

### Establishing Causality

Let's return to the 1854 cholera outbreak and the question before John Snow: did
something in the water of the Broad Street public water pump cause cholera? If so,
this would explain the higher incidence rate of cholera in residences near the 
pump and it would also explain the other anomalies he found in the data (see
@sec-cholera).

The map Snow drew in 1854 (@fig-cholera-map) might be convincing to us, his
contemporaries did not feel that way. For one, he could not **prove** that the Broad
Street well water caused the cholera cases. And his hypothesis was inconsistent
with the prevailing theory of the time, that cholera was caused by airborne 
particles (miasma) from dirty or decaying biological material.

The analysis of the cholera map established a correlation rather than causation 
because of the possibility of **confounding** factors: variables that can mask
or distort the effect of other variables. In the 1960s it was shown that coffee
drinkers had higher rates of lung cancer than non-coffee drinkers. Some thought
this was implication of coffee as a cause of lung cancer. That is incorrect.
The association is due to a confounding factor: coffee drinkers at the time 
were more likely to be also smokers. Coffee drinking was associated with lung
cancer but does not cause the disease.

In the case of the 1854 cholera outbreak, there could have been confounding 
factors that caused cholera incidences in the Broad Street area to be higher,
whether the water was or was not the cause of the disease. Maybe the residents
of that poorer neighborhood had a different diet that caused the disease. Maybe
they had occupations that made it more likely to be exposed to a harmful agent.
Maybe. Maybe. Maybe.

In order to establish a causal link between two variables, the confounding factors
must be accounted for---at least beyond a reasonable doubt. Otherwise there will 
always be some reason to believe another mechanism was at work.

How one goes about accounting for confounding factors depends on the domain. The
first question is whether the factors are controllable in some form. If so, we 
can use **experimentation** to set up controlled environments in which the only
thing that can reasonably explain the effects we are seeing are the factors we
deliberately manipulate. This is the area of **experimental design**. 

If you cannot manipulate and control factors in an experiment, maybe you are lucky to
find data where the confounding factors have already been controlled for you.
Sometimes real life runs these quasi-experiments for us and eliminates the
confounding factors. Although the data is observational rather than experimental 
(see below), it can go a long way toward establishing causality. In @sec-cholera-deeper
we discussed a second, deeper analysis John Snow conducted in which he compared 
cases between customers of the Lambeth and the Southward \& Vauxhall water companies.
For all intents and purposes the groups serviced by the two companies were identical
except for the source of the water. Lambeth's water was drawn upriver from sewage
discharge into the River Thames and was cleaner than the water from Southwark \&
Vauxhall, which drew water below the sewage discharge. The much higher cholera
incidence in the group supplied by Southwark \& Vauxhall was sufficient evidence
to implicate the water.

In domains and applications where experimentation is not possible and confounding
factors are present, we try to establish causation by a process called [**causal inference**](https://en.wikipedia.org/wiki/Causal_inference). By studying which 
variables act on each other, causality can be inferred.


#### Observational and experimental data




## Bias and Variance Tradeoff {#sec-literacy-bias-variance}

### Overfitting {#sec-literacy-overfitting}

### Underfitting

## All Models are Wrong--Some are Useful

In a 1976 paper, George E.P. Box declared "All models are wrong" [@GEPBox1976].
Later, he added a qualification which turned into a frequently cited quote 
about modeling: 

>*All models are wrong, some are useful.* [@BoxDraper_1987, p. 424].

### Compartmental Models in Epidemiology

SIR (Susceptible--Infectious--Recovered) model is a standard class of compartmental
models in epidemiology, describing how an infectious disease moves through a population. 
On the surface this makes sense: at each point in time an individual is in one of 
three states, called compartments: 

* You have not had the disease but you are susceptible to it (S compartment)
* You are infected by the disease (I compartment)
* You are recovered from the disease, or dead (R compartment)

A vaccination, then, is a shortcut that moves an individual directly from the 
S to the R compartment, bypassing the infected state.

However, there are a number of assumptions in the SIR model that can invalidate
the model for some diseases and circumstances:

1. The disease progresses in only one direction, from S to I to R. 
2. Everyone is equally susceptible and behaves the same way
3. Everyone is equally likely to be vaccinated, if a vaccine is available
4. All members of the populations intermingle at random

The rate at which the disease spreads through the population is measured by the
**basic reproduction** number, $R_0$. This number, which we became all too 
familiar with during the COVID-19 pandemic, measures the number of uninfected 
people expected to catch the disease from an infected individual. An $R_0$ of
3 means that someone who contracts the disease is expected to pass it on to three
other individuals. In the absence of vaccines or quarantines, any disease with
$R_0 > 1$ will eventually spread to the entire population.


## Agent-based Models

A different tactic than to rely on *sophisticatedly simple* models that abstract
the essence of the thing we wish to study is to simulate the process in all its
complexity, essentially building a digital twin of the thing we wish to study.

That is essentially the approach taken in weather prediction. Rather than relying
on statistical models that predict based on historical data, weather predictions
are based on complex physical simulations of the atmosphere. 


