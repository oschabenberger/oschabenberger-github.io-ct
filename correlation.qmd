
# Correlation and Causation {#sec-corr-cause}

:::{.callout-tip title="Quote"}

::: {.flushright}
Just because two variables have a statistical relationship with each other does not mean \
that one is responsible for the other.  For instance, ice cream sales and forest fires \
are correlated because both occur more often in the summer heat.  But there is no \
causation; you don't light a patch of the Montana brush on fire when you buy a\
pint of Häagan-Dazs.\
[Nate Silver, The Signal and the Noise]{.quoteauthor}
:::
:::

## Introduction

One of the key tasks in analyzing data is uncovering relationships between things.
Describing the statistical behavior of a single variable is interesting. Studying
how two or more variables behave **together** is really interesting. That is 
how we uncover mechanisms, relationships, associations, and patterns. And if 
things go really well, we might discover cause-and-effect relationships.

You might have heard the saying

:::{.quote}
correlation does not imply causation
:::

What do we mean by that? 

Causation implies that one thing is the result of another thing; they 
stand in a cause-and-effect relationship to each other. The gravitational pull
of the moon on earth's oceans causes the tides. An accident causes a traffic jam.
Smoking causes an increase in the risk of developing lung cancer.

Correlation, on the other hand, is about establishing **association** between 
attributes. The weight of a person is correlated with their height. Taller 
people tend to be heavier but height alone is not the only factor affecting 
someone's weight. Smoking is correlated with alcoholism but does not cause it.

@fig-lemon-acc displays the relationship between highway accidents in the U.S. and
lemon imports from Mexico for a period of five years, from 1996--2001. The U.S.
Dept. of Agriculture tracks agricultural imports and exports, the U.S. National
Highway Traffic Safety Administration (NHTSA) tracks highway fatalities. Neither
federal agency probably thought much about the data collected by the other agency.
But when put together, voilà. A clear trend emerges!

![Relationship between highway fatalities and lemon imports from Mexico.](images/spurious1.png){#fig-lemon-acc fig-align="center" width=65% .lightbox}

If the relationship in @fig-lemon-acc is causal, public policy to reduce highway
fatalities is very clear: reduce fresh lemon imports from Mexico! Clearly, this is not
a causal relationship. There must be another explanation why the variables in
@fig-lemon-acc appear related. 

Compare this situation to John Snow's investigation
of the relationship between water quality and cholera incidences in 19^th^ century
London (@sec-cholera). Snow found higher cholera incidences in houses closer
to the Broad Street public water pump. There was a strong association between
cholera cases and proximity to the pump. But did the pump---or more precisely the
water from the pump or something in the water---**cause** cholera? Today we know that
cholera is caused by the bacterium *Vibrio cholerae*, but that discovery was not
made until 1883. 

## Correlation and the Correlation Coefficient

We experience correlation when one attribute changes with another. When the 
attributes are continuous (see @sec-data-types), we can display their association
with a scatterplot. A positive correlation then implies that the point cloud
has a positive slope, as one attribute increases the other one tends to increase 
as well (@fig-corr-pos). When the correlation is negative, an increase
in one attribute is associated with a decrease in the other attribute (@fig-corr-neg).

![Positive correlation.](images/CorrelationPositive.png){#fig-corr-pos fig-align="center" width=75% .lightbox}

![Negative correlation.](images/CorrelationNegative.png){#fig-corr-neg fig-align="center" width=75% .lightbox}

While the direction of the point cloud indicates whether the correlation (association)
is positive or negative, the tightness of the point cloud indicates the strength
of the association (@fig-correlations).

![Correlations of different strength and directions. The numbers above the point clouds indicate the strength and direction of the correlation](images/different_correlations.png){#fig-correlations fig-align="center" width=85%}

When we are dealing with discrete attributes, the association cannot be revealed
through a point cloud. Instead, we **cross-tabulate** the frequency of occurrence
of the attributes. 

:::{.example}
::::{.example-header}
Example: Rater Agreement
::::
::::{.example-container}
@tbl-rater-agree shows the results of a study where insect 
damage on 236 agricultural fields was classified into
5 damage categories by two different inspectors.

| **Rater 2** | 1 | 2 | 3 | 4 | 5 | **Total** |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| **1** | 10 |  6 |  4 |  2 |  2 | 24 |
| **2** | 12 | 20 | 16 |  7 |  2 | 57 |
| **3** |  1 | 12 | 30 | 20 |  6 | 69 |
| **4** |  4 |  5 | 10 | 25 | 12 | 56 |
| **5** |  1 |  3 |  3 |  8 | 15 | 30 |
| **Total**| 28 | 46 | 63 | 62 | 37 | 236 |

: Results of rating 236 experimental units by 2 raters {#tbl-rater-agree .striped}

For example, 16 experimental units were assigned to damage category 3 by rater 1
and to damage category 2 by rater 2. There is relatively strong association 
between the ratings, the majority of the counts fall on the diagonal of the 
table and in the cells immediately off the diagonal (where the raters disagree
by one damage category).
::::
:::

Another example of cross-tabulating counts to demonstrate association is
@tbl-chol-rate2 in John Snow's cholera study. It shows that cholera deaths
are 10 times more likely to occur in homes supplied by the Southward \& Vauxhall
water company than in homes supplied by the Lambeth water company.


---

### Corrrelation Coefficient

The strength of the correlation between continuous attributes is measured by the 
**correlation coefficient**, which ranges from -1 to 1. Both of these extremes are called 
perfect correlations and happen when all points fall on a perfect line, without 
variability about the line. The relationship is **deterministic**.
Linear mathematical relationships exhibit such patterns, for example, the relationship 
between degree Celsius and degree Fahrenheit (@fig-fahrenheit):
$$
^\circ F = {^\circ C} \times \frac{9}{5}  + 32
$$

```{r, echo=FALSE, fig.align='center', out.width="75%"}
#| fig.cap: Linear relationship between $^\circ F$ and $^\circ C$.
#| label: fig-fahrenheit
#| 
degC <- seq(-10,40,1)
degF <- degC * 9/5 + 32
plot(degC,degF,las=1,bty="l",type="l",lwd=2)
lines(x=c(0,0),y=c(10,32), lty="dashed")
lines(x=c(-12,0),y=c(32,32),lty="dashed")
```

This raises another caution about relying on correlation metrics: the relationship between attributes
can be quite strong, but their degree of **linear** relationship can be low.
@fig-corr-nonlin shows two variables with a strong nonlinear relationship. 
$Y$ decreases with increasing $C$ for values $X < 0$ and $Y$ increases with $X$
for values $X > 0$. When the standard linear correlation coefficient is calculated,
it turns out to indicate a very weak relationship between the variables---a 
very weak **linear** relationship. The takeaway is not to only focus on reported 
measures of association but to also examine the relationships visually.

```{r, echo=FALSE, fig.align='center', out.width="75%"}
#| fig.cap: Strong nonlinear relationship with small (linear) correlation coefficient.
#| label: fig-corr-nonlin
#| 
set.seed(234)
x <- runif(100,min=-2,max=2)
y <- 0.9 * x^2 + rnorm(100,0,0.1)
r <- cor(x,y)

plot(x,y,las=1,bty="l")
text(x=-0.8,y=3,labels=paste("Correlation coefficient:",round(r,4)))
```


### College Rankings Data

Computing correlation coefficients between the variables in a data set is 
part of exploratory data analysis. In @sec-steps-r-eda we performed EDA for the
College rankings data. Now let us compute the correlation coefficients.

First, we grab the data from the `ISLR2` library and attach it to the `R` session.

```{r, message=FALSE}
library(ISLR2)
data(College)
attach(College)
```

The `cor()` function computes correlation coefficients between pairs of 
variables or sets of variables. The next statement computes the correlation 
between graduation rate and out-of-state tuition for the 777 colleges in the data 
frame:

```{r}
cor(Grad.Rate, Outstate)
```

The two variables have a modest positive correlation of `{r} round(cor(Grad.Rate, Outstate),4)`.

To see the correlation coefficients between graduation rates and the other numeric
variables in the data frame, list the variable for which you want to obtain
the correlation coefficients second:

```{r}
cor(College[,-1], Grad.Rate)
```

Because we cannot compute the correlation with a factor variable (`Private`),
the first variable is omitted from the data frame by specifying `College[,-1]`.

The graduation rates are not very strongly correlated with any of the variables.
Note that the correlation of a variable with itself is always 1.

Finally, to obtain all pairwise correlations between numeric variables in the
data frame we request the computation of the correlation matrix. This results
in a large 17 x 17 matrix. To help with readability the result is displayed
with three decimal places.

```{r}
round(cor(College[,-1]),3)
```

It is much easier to see what is going on with all pairwise correlations when
the matrix is displayed graphically. The strength and direction can be displayed
with colors. The diagonal values can be omitted as they are known to be 1.

The `corrplot` function in the package by the same name creates nice visualizations
of correlation matrices. Before running the code in the chunk below, you will
need to install the `corrplot` package first, unless it is already installed
on your system:

```{r, eval=FALSE}
install.packages("corrplot")
```

Now we can compute the **heatmap** of the pairwise correlation coefficients (@fig-corrplot).

```{r, message=FALSE, warning=FALSE, fig.align="center", out.width="90%"}
#| fig.cap: Visualization of pairwise correlations for College data. 
#| label: fig-corrplot
library(corrplot)
cormat <- cor(College[,-1])
corrplot(cormat, diag=FALSE, method="color")
```

You see high positive correlations (dark blue color) in the upper left corner of
the heatmap. The number of applications received (`Apps`) is very highly correlated
with the number of applications accepted (`Accept`)---this is not a big surprise.

:::{.assignment}
::::{.assignment-header}
Assignment: College Ranking Correlations
::::
::::{.assignment-container}
1. Are there surprising positive or negative correlations in the matrix?

2. Which of the strong correlations are not surprising to you?

3. Can you explain some of the weak (near zero) correlations?

4. A relatively strong negative correlation exists between `Expend` and
`S.F.Ratio`. A similar correlation exists between `Outstate` and `S.F.Ratio`.
How do you interpret/explain these dependencies?

::::
:::


## Spurious Correlations

It seems obvious that just because two attributes vary with each other---are
correlated---one should not infer that they are cause and effect of each other.
Unfortunately, that leap of faith is often made and can lead to very problematic
decisions.

![Chocolate consumption and number of Nobel laureates.](images/Chocolate.png){#fig-chocolate-corr fig-align="center" width=75% .lightbox}

@fig-chocolate-corr displays the number of Nobel laureates per 10 million population
against the chocolate consumption (in kg per capita and year) for various countries
[@Messerli_2012].
An upward trend is clearly noticeable. A greater per-capita chocolate consumption
is associated with a lager number of Nobel laureates. Whoa! If the two variables
stand in a cause-effect relationship then we have a simple recipe to increase
Nobel prizes: we all should eat more chocolate. While one can argue the benefits 
of chocolate for cognitive function, what we have here is a simple correlation. 
The two attributes, number of Nobel laureates per 10 million population and chocolate 
consumption per capita, are related. If one increases so does the other. But why?

This is an example of a **spurious** correlation. The variables are not really
dependent on each other, a relationship is induced in some other way. In this 
particular example, the correlation was "found" by cherry-picking the data:
only four years of chocolate consumption were considered on a limited number of 
chocolate products and no data prior to 2002 was used. The number of Nobel 
laureates is a cumulative measure that spans a much longer time frame.

It appears that the data were organized in such a way as to suggest a relationship 
between the variables. 

You can find spurious correlations everywhere, without manipulating the data.
Here are some examples and the reasons why the data appear correlated.

### Coincidence

Forecasting economic conditions is difficult and highly valuable. Since the end
of World War II there have been only eleven economic recessions. On the other 
hand we are producing thousands of economic indicators. The government alone 
generates 45,000 economic statistics each year [@Silver2012, p.185].

So it should not be surprising that when sifting through all those variables we
find some that appear to go up or down together, just by coincidence.

A famous example is the Super Bowl winning conference as an indicator of economic
performance. Between 1967 and 1997, in years when the team from the original NFL 
won, the stock market went up by 14\%. When a team from the original AFL won the 
stock market decreased by almost 10\%. Through 1997, the Super Bowl winner "predicted"
correctly the direction of the stock market in 28 out of 31 years [@Silver2012].
Since 1998 the trend has reversed and the stock market is doing better when an 
AFL team won the Super Bowl. Coincidence during a period of time leads to mistake
noise for signal.

Another example of coincidence being mistaken for correlation is 
[Paul, the octopus](https://en.wikipedia.org/wiki/Paul_the_Octopus) who correctly
predicted the winner in 2008--2010 international soccer matches 12 out of 14 times,
an 85\% accuracy. Since this success rate is unlikely to happen by chance, it was
determined that Paul the octopus has divine powers. When Paul got it wrong in 
a 2010 FIFA World Cup game between Germany and Spain, the German fans called for
Paul to be eaten and the Spanish Prime Minister offered Paul asylum.

### Latent Variables

A correlation between variables A and C can be induced by another variable, say B.
If A is correlated with (or caused by) B and C is correlated (or caused by) B,
then plotting A versus C indicates a correlation between the two variables.
However, the relationship is induced by the **latent variable** B.

![Spurious correlation.](images/spurious3.jpg){#fig-spurious-corr fig-align="center" width=65%}

Latent variables are often the real reason why things appear related when we
deal with variables that depend on population size or common factors 
such as the weather or time. @fig-spurious-corr shows the close relationship over
time between the number of high school graduates and donut consumption. More 
donut consumption appears related to more high school graduates. Notice that
we are not plotting graduation **rates**, these would most likely not have any
relationships with donut consumption. The latent variable at work in @fig-spurious-corr
is the size of the population over time. As the population increases, more donuts
are consumed and more people graduate from high school.

A similar spurious correlation is that between ice cream sales and forest fires.
Both increase during the summer heat and decrease in the winter.

You can imagine the horrible public policy decisions one would make by mistaken
those spurious correlations for cause and effect relationships.

### Induced Correlation

Another interesting mechanism to induce correlation is by introducing a 
mathematical dependence between two attributes. A famous example is the relationship
between birth rate and the density of storks.

![Storks and Babies](images/Stork.png){#fig-stork-baby fig-align="center" width=45%}

In central Europe a persistent myth is that storks bring babies. [Movies](https://en.wikipedia.org/wiki/Storks_(film))
were made about it! The origin of the association probably goes back to medieval 
days when conception was more common in mid-summer during the celebration of the 
summer solstice which is also a pagan holiday of marriage and fertility. The 
white stork is a migratory bird that flies to Africa in the fall and returns to 
Europe nine months later. Hence the connection was made that storks brought
the babies.

Although the myth has been debunked, there have been several studies of the connection 
between fertility and the stork abundance. @Neyman_1952 describes a study of 54 
counties that comprises the following attributes

- $W$: Number of women of child-bearing age in the county (in 10,000)
- $S$: Number of storks in the county
- $B$: Number of babies born in the county

Since it is likely that these numbers increase with the size of the county, the 
variables analyzed were $Y = B/W$ and $X=S/W$, the birth rate per 10,000 women 
and the density of storks per 10,000 women. A plot of these variables and a
smooth estimate of their trend is shown in @fig-stork-trend. 
 
![Storks and babies.](images/Storks_and_Babies.png){#fig-stork-trend fig-align="center" width=75%}

It certainly appears that the birth rate increases with the density of storks.
Could the myth be true? Is something else going on?

The trend in @fig-stork-trend is induced by expressing both variables as ratios
with the same variable, $W$, the number of women of child-bearing age. If
$S$ and $B$ are unrelated, $S/W$ and $B/W$ now share information because they
are expressed relative to another variable.

:::{.assignment}
::::{.assignment-header}
Assignment: Mozzarella and Engineering Degrees
::::
::::{.assignment-container}
@Spiegelhalter2021 cites the strong correlation (coefficient 0.96) between the
annual per-capita consumption of mozzarella cheese in the U.S. in the period
2000--2009 ($X$) and the number of civil engineering doctorates awarded in those
years ($Y$).

1. How would you interpret this relationship if $X$ causes $Y$?
2. If this relationship is spurious, what could explain it?
3. Correlation is a symmetrical relationship, mathematically, $\text{Cor}(X,Y) = \text{Cor}(Y,X)$.
Causation on the other hand is asymmetrical. If $X$ causes $Y$ does not imply 
that $Y$ causes $X$. $Y$ causing $X$ is called **reverse causation**. What does
reverse causation mean in the Mozzarella--Engineering Ph.D. example?
::::
:::

## Establishing Causality

Establishing a causal link between factors is the holy grail of scientific study.
When we prove that one event is the result of another event, we have established
new, irrefutable knowledge, beyond a reasonable doubt.

Establishing cause and effect is also quite difficult. @Spiegelhalter2021 [p. 97]
calls causation a "deeply contested subject". You get a splinter in your finger
and it hurts. Did the splinter cause the pain? Is it possible that the finger
would have abruptly started to hurt if it wasn't for the splinter? If it was me, 
it would be pretty obvious to **me** that the splinter caused the pain. 

But wait. Not everyone has the same level of pain tolerance. The splinter that 
causes me much agony might be a mere scratch, hardly noticeable, for someone else. 
How do we take this variability in the population into account in making statements 
about causality? 

When we say that smoking causes lung cancer, we do not claim that every smoker will
get the disease. Some smokers do not get lung cancer and there are lung cancer
patients who never smoked. The second leading cause of lung cancer deaths in 
the U.S. is exposure to Radon gas. That is why in many regions Radon inspections
are required prior to purchasing homes. A more precise statement would be that smoking causes
an increase **in the likelihood** of getting lung cancer. It is not a statement
about what happens to Joe or Diana. The statistical notion of causation between
$X$ and $Y$ means that if $X$ occurs, $Y$ **tends to occur** more or less often. The
statistical notion of causation is not deterministic [@Spiegelhalter2021, p. 99].

In a study about the association between repeated head impacts (RHI) and chronic
traumatic encephalopathy (CTE), @Nowinski_et_al state that causation is an 
interpretation, not an entity. In studies involving complex environmental exposures 
causation is a continuum from highly unlikely to highly likely, and no single study 
can prove causation.

In the presence of uncertainty some scientific standard needs to be met in order
for us to claim that something has been proven and even then, we are not making
statements that the something  will happen every time, only that the proportion
of times that it will happen has been affected.

### Confounding

Let's return to the 1854 cholera outbreak and the question before John Snow: did
something in the water of the Broad Street public water pump cause cholera? If so,
this would explain the higher incidence rate of cholera in residences near the 
pump and it would also explain the other anomalies he found in the data (see
@sec-cholera).

The map Snow drew in 1854 (@fig-cholera-map) might be convincing to us, his
contemporaries did not feel that way. For one, he could not **prove** that the Broad
Street well water caused the cholera cases. And his hypothesis was inconsistent
with the prevailing theory of the time, that cholera was caused by airborne 
particles (miasma) from dirty or decaying biological material.

The analysis of the cholera map established a correlation rather than causation 
because of the possibility of **confounding** factors: variables that can mask
or distort the effect of other variables. In the 1960s it was shown that coffee
drinkers had higher rates of lung cancer than non-coffee drinkers. Some thought
this was implication of coffee as a cause of lung cancer. That is incorrect.
The association is due to a confounding factor: coffee drinkers at the time 
were more likely to be also smokers. Coffee drinking was associated with lung
cancer but does not cause the disease.

A confounding factor is related to both the cause and the effect and can mislead
us into attributing too much or too little importance to the potential cause. 
Variables such as age, time, temperature, population size are often confounding
factors because they act on the factor of interest and on the outcome of interest.
For example, age is a confounding factor in studies of exposure to harmful agents.
If damage from the agent is more prevalent in older people, age can be a confounding
factor because older people have been exposed longer. 

When spurious correlations are induced by latent variables, the latent variable
is a confounder. The apparent correlation between ice cream sales and shark 
attacks is explained by the confounder *temperature*. Ice cream sales and 
shark attacks increase with temperature as more people buy ice cream and more
people go to the beach.

:::{.assignment}
::::{.assignment-header}
Assignment: 1854 Cholera Outbreak
::::
::::{.assignment-container}
In the case of the 1854 cholera outbreak, there could have been confounding 
factors that caused cholera incidences in the Broad Street area to be higher,
whether the water was or was not the cause of the disease. Maybe the residents
of that poorer neighborhood had a different diet that caused the disease. Maybe
they had occupations that made it more likely to be exposed to a harmful agent.
Maybe. Maybe. Maybe.

What other confounding factors can you think of that would mask, amplify,
or suppress the incidence of cholera?
::::
:::

In order to establish a causal link between two variables, the confounding factors
must be accounted for---at least beyond a reasonable doubt. Otherwise there will 
always be some reason to believe another mechanism was at work. There are a few
principal mechanisms to deal with confounding variables:

1. Adjustment
2. Stratification
3. Randomization

We will discuss these in turn, but note that they are not mutually exclusive.
A study might involve experimentation with randomly assigned treatments as well
as model adjustments for confounding variables.
 
### Adjustment

Adjusting for confounding variables means to include the variables in models
that describe the relationship between the factor of interest and the outcome
of interest. Consider the Radon exposure example above. A model to describe the
relationship between exposure $x$ (in picocuries per liter air) and cancer risk 
could be written in two parts:
$$
\begin{align}
\eta &= \beta_0 + \beta_1 x + \beta_2 \text{ age} \\
\Pr(\text{Develops cancer}) &= \frac{1}{1+\exp\{-\eta\}} \\
\end{align}
$${#eq-radon-model}

The first term of the model, $\eta$, is called the linear predictor and is a function
of the variables that materially determine the cancer risk. In addition to the 
exposure $x$, the linear predictor also contains a term for a person's age. The
second expression in @eq-radon-model transforms the linear predictor into a 
probability---it is called the logistic transformation.

This model allows us to estimate how much of the cancer risk is due to the
level of radon exposure and how much is due to the age of the person. With the 
variable of interest ($x$) and the confounding variable (age) disentangled we can 
make statements about the risk of cancer as a function of radon exposure and age.

An important aspect of adjusting for confounding variables is the functional
relationship between the variables. In @eq-radon-model the two variables enter
the linear predictor in an additive fashion. Maybe this is not the appropriate
adjustment. If the effect of age on cancer risk changes with the level of radon 
exposure then we say that the two variables **interact**. A model that includes 
a multiplicative interaction tterm then might be more appropriate:
$$
\eta = \beta_0 + \beta_1 x + \beta_2 \text{ age} + \beta_3 x\,\text{age}\\
$$

In other words, determining **how** to model the relationship of confounding 
variables on other variables and on the outcome of interest, is of great importance.


### Stratification

Stratification is an approach to deal with confounding factors that are 
qualitative. It means to examine relationships separately for each level of
the confounder. To see if there is a general relationship between ice cream sales
and shark attacks we can examine the association for different temperature 
ranges. As a surrogate for that we can look at the association by month or by
season.

When performing analyses overall and comparing them to analyses within groups 
(within strata) we can run into situations where the two seem to provide 
contradictory results. This is known as Simpson's paradox.

#### Simpson's Paradox

The paradox is named after Edward Simpson who described it in a technical paper
in 1951, but the phenomenon has been known much longer. It is also not a paradox
as it does not lead to nonsensical outcomes or a contradiction. What we know as
Simpson's Paradox is simply the result of looking at an aspect from two viewpoints:
The trend that we see in combined data can reverse when we look at the data in
groups.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(MASS)
library(tidyverse)

set.seed(345)

g1 <- as.data.frame(mvrnorm(n    =1000, 
                            mu   =c(0.4,0.4), 
                            Sigma=rbind(c(2,-0.7),c(-0.7,2))))

g2 <- as.data.frame(mvrnorm(n    =1000, 
                            mu   =c(3,3), 
                            Sigma=rbind(c(4,-0.5),c(-0.5,4))))

g3 <- as.data.frame(mvrnorm(n    =1000, 
                            mu   =c(6,6), 
                            Sigma=rbind(c(3,-0.7),c(-0.7,3))))
g1$Group <- c("Group 1")
g2$Group <- c("Group 2")
g3$Group <- c("Group 3")

df <- rbind(g1,g2,g3)
names(df) <- c("X", "Y","Group")
```

@fig-simpson-all displays a scatter plot of two variables and a linear regression
trend. The slope is positive, the average value of $Y$ increases with the 
value of $X$.

The data in @fig-simpson-all consists of three groups and when the regression
analysis is performed separately for each group, a different picture emerges.
Within each group the regression relationship indicates a negative slope, 
the opposite of the trend in the ungrouped data (@fig-simpson-group).

```{r, echo=FALSE, message=FALSE, fig.align='center', out.width="75%"}
#| fig.cap: Combined data and regression trend.
#| label: fig-simpson-all

pp <- df %>% ggplot(aes(x=X, y=Y)) +
    geom_point(color="red", size=0.7) + 
    geom_smooth(method='lm', se=FALSE, color="black")
print(pp)
```

```{r, echo=FALSE, message=FALSE, fig.align='center', out.width="75%"}
#| fig.cap: Grouped data and group-specific regression trends.
#| label: fig-simpson-group

pp <- df %>% ggplot(aes(x=X, y=Y, group=Group, col=Group)) +
    geom_point(size=0.7) + 
    geom_smooth(method='lm', se=FALSE, col='black')  
print(pp)
```

The apparent contradiction comes about because the three groups have different
centers and orientation. When "stacked" they create a single point cloud with a positive slope.
As mentioned previously, this is not really a paradox, both ways of looking at
the data are sensible and the results are meaningful either way. The "paradox" lies
in the fact that the two views lead to seemingly different conclusions about
the relationship between the variables.

Examples of Simpson's Paradox with qualitative data can be found in college 
admissions data. [Wikipedia](https://en.wikipedia.org/wiki/Simpson%27s_paradox)
shows the apparent gender bias effect for 1973 data from UC Berkeley. @Spiegelhalter2021
shows data for Cambridge from 1996. The table in @Spiegelhalter2021 [p. 111] is reproduced
below as two separate tables.

|        | Women     |            |         | Men | | | 
|--------|---:|---:|---:|---:|---:|---:|
|        |**Applied**| **Accepted**| **\%** | **Applied** | **Accepted** | **\%**|
| Total  | 1,184 | 274 | 23\% | 2,740 | 584 | 24\%

: Application and acceptance rates at Cambridge in 1996 in STEM disciplines for men and women. {#tbl-camb-all .striped}

@tbl-camb-all shows the overall acceptance rates for men and women, with the
former slightly higher by one percent.

|        | Women     |            |         | Men | | | 
|--------|---:|---:|---:|---:|---:|---:|
|        |**Applied**| **Accepted**| **\%** | **Applied** | **Accepted** | **\%**|
| Computer Science    |  26 |  7 | 27\% | 228 |  58 | 25\% |
| Economics           | 240 | 63 | 26\% | 512 | 112 | 22\% |
| Engineering         | 164 | 52 | 32\% | 972 | 252 | 26\% |
| Medicine            | 416 | 99 | 24\% | 578 | 140 | 24\% |
| Veterinary Medicine | 338 | 53 | 16\% | 180 |  22 | 12\% |

: Application and acceptance rates at Cambridge in 1996 by STEM discipline.
{#tbl-camb-stem .striped}

@tbl-camb-stem shows the applications and acceptance rates by discipline. In each
discipline the acceptance rate for women is at least as high as that for men,
in fact it is higher than that for men, except for Medicine. 

How do we explain this apparent contradiction? In each discipline the acceptance
rate for women is as high or higher than that for men, but overall the acceptance
rat for women is lower. The explanation is that women were more likely to apply
for subjects that have high application numbers and are more difficult to get in.
64\% of the applications from women went to Medicine and Veterinary Medicine 
(416 + 338 out of 1,184). Only 30% of the male applications went to those subjects.
Men applied disproportionately more to Engineering, which has a higher acceptance
rate than the other STEM disciplines. It seems that there is no gender bias in
these admission numbers, the lower overall admission rate for women is the result
in women applying in larger numbers to STEM disciplines that are difficult to
get into.


### Randomization

**Randomization** is a simple and effective mechanism to create probabilistic
equivalence in data and takes two forms: random **selection** and random 
**assignment**. Random does not imply haphazard or arbitrary, the way in which 
selection or assignment is randomized obeys probability distributions. Because we
specify the distribution according to which selection or assignment occurs, we
understand the probabilistic behavior of the data we collect. 

For example, we select a **random sample** of people from a population such that each person
has the same chance of entering the sample. This guarantees that the attributes
of the population are represented properly in the sample. The proportion of
persons of different age, gender, race, etc. in the sample will be representative of the 
population from which the sample is drawn, although the exact proportions will
not be identical in a particular sample. If we were to draw a sample of $n$ people 
by a non-random mechanism, for example, by taking the first $n$ folks who drive
through an intersection, or $n$ airline passengers on a given day, or $n$ residents
of a particular neighborhood, or the first $n$ entries in the list of the U.S. 
Census Bureau, our sample would not be representative of the population we 
are interested in studying. The sample would suffer from **selection bias**, conclusions
drawn from analyzing the data in the sample would not apply to the population 
as a whole. Note that random sampling from a non-representative list also suffers
from selection bias. Randomly sampling social media posts does not give insight into the opinions of
the general population because social media users are not representative of the
general population. Asking questions of a random sample of drivers passing 
through an intersection does not properly represent those who do not drive or
live elsewhere.

The random mechanism in random selection has a balancing property. It ensures
that sub-groups are not over represented or under represented in the sample, provided
that the sample is sufficiently large. This balancing property is also key for the
second form of randomization: **random assignment** when conditions are manipulated
on purpose. This leads us to experimentation.


### Experimentation--The Randomized Controlled Trial (RCT)

#### Example: RCBD in Agriculture

Suppose you wish to study how poppies grow on an agricultural field.
The poppies are subject to varying growing conditions due to differences in the
soil characteristics, topography, weather, plant-to-plant variations, and so on.
We are particularly interested to see how six different fertilizer applications
affect the poppy growth. The conditions that affect poppy growth can be grouped
into three categories:

1. Conditions we manipulate
2. Conditions we do not manipulate but know about
3. Conditions we do not know about (lurking factors)

The fertilizer treatments fall into the first category. We can apply parts of the 
field and apply fertilizer A to it, other parts receive fertilizer B, and so on.
Suppose that the field is large and sloped and we suspect a gradient in soil nutrients and
water. This falls into the second category. We do not create or manipulate the 
soil and water conditions, but we are aware of them. They are a confounding factor.
All other potential influences of poppy growth fall into the third category.

@fig-rcbd-poppies displays a popular layout for running such a fertilizer 
experiment in agricultural science. It is called a randomized complete block
design (RCBD). The experimental area is divided up into separate blocks, in this
case four of them.

![Experimental layout for poppy experiment.](images/RandomizedBlocks.png){#fig-rcbd-poppies fig-align="center" width=85% .lightbox}

The blocks are chosen so that the fields within a block---we call them **experimental 
units**---are homogeneous with respect to the conditions we know about.
This is the technique to control confounding factors in category 2 by stratification
and adjustment. Within each block the fertilizer treatments are assigned 
**randomly** to the six experimental units. This random assignment balances out
the effects of the confounding factors we do not know about (category 3). If we 
were to assign treatments to experimental unit in a deterministic way---for example,
treatment A always to the upper left unit, treatment B right next to it, etc.---it
is possible that confounding factors associated with the position in the block
mask or distort the effect of the treatment. We would then not really compare
treatment A to treatment B, but a blend of treatment effect and location effect.

Finally, because the world is uncertain, we do not apply the treatments only 
once. We use multiple blocks, each with a separate assignment of treatments to 
experimental units to **replicate** the per-block layout. This replication allows
us to measure the inherent variability in poppy growth, unaffected by treatment
or confounding factors.

If the experimental units in our agricultural science experiment contain more 
poppies than we can harvest and analyze in the lab, we would select some 
of them for lab analysis. This would be done by random selection to make sure
that the plants analyzed in the lab are representative of the plants growing 
on the experimental unit.

In this RCBD with four blocks and six treatments we encounter all techniques to
manage confounding factors: stratification, adjustment (because block effects will
be included in the model during analysis), and randomization. As a result, we
are allowed to make cause-and-effect statements about the treatment factor we
manipulated, the fertilizer. If plants grown under the fertilizer A treatment
are taller than those grown under fertilizer B, then there are only two possible
explanations:

1. Fertilizer A causes poppies to grow taller compared to fertilizer B
2. Coincidence: the height difference we are seeing is due to chance 

Other explanations can be ruled out because we controlled the experiment for
other factors.

In order to separate the two remaining explanations, we analyze the size of the 
treatment differences relative to the inherent variability in poppy growth. That
is the reason why the experiment uses multiple blocks rather than a single block.
The replication of treatment assignments allows us to estimate that inherent 
variation. If poppy growth varies widely, then a small difference in height 
between plants from treatment A and treatment B will not surprise us. If 
inherent growth variation is small, observed differences between treatments point
at the fertilizer as the cause.

#### Other Experiments

Experimentation with random assignment of conditions has a long history. It 
started in agricultural experiments and has since permeated many domains. 
Randomized clinical trials are common to test medical drugs, devices, and 
treatments. Industrial experimentation is used to find the best manufacturing
conditions for products. 

Randomized trials are also used in the social sciences.
@Spiegelhalter2021 [p. 107] cites the Study of the Therapeutic Effects of 
Intercessory Prayer (STEP) by @Benson_et_al to answer the question whether being
prayed for improves the recovery of patients after coronary artery bypass graft (CABG) surgery.
The Methods section of the paper describes the randomized experiment:

>*Patients at 6 US hospitals were randomly assigned to 1 of 3 groups: 604 received 
intercessory prayer after being informed that they may or may not receive prayer; 
597 did not receive intercessory prayer also after being informed that they may or 
may not receive prayer; and 601 received intercessory prayer after being informed 
they would receive prayer. Intercessory prayer was provided for 14 days, starting 
the night before CABG. The primary outcome was presence of any complication within 
30 days of CABG. Secondary outcomes were any major event and mortality.*

The study concludes

>*Intercessory prayer itself had no effect on complication-free recovery from CABG, 
but certainty of receiving intercessory prayer was associated with a higher 
incidence of complications.*

Knowing that they were being prayed for might have made patients more uncertain,
wondering whether they are so sick that they had to call in the prayer team.

---

Experimentation with random assignment is also used frequently in the technology
industry, the technique is known as A/B testing. Only two treatments are being
evaluated (A and B), one is typically a current product or design. Users of the 
product/design are randomly directed to the A or B option and the attribute
of interest is measured (click-through rate, time on page, use of features on page,
checkout, purchase amount, etc.). We are all participating in these ongoing A/B
experiments when we operate online. Google is said to run about 10,000 A/B
experiments every year.

### When Experimentation is Not Possible

Experimentation with random assignment of treatments is the gold standard to 
establish cause and effect. But it is not always possible to go down that path.

Some systems defy manipulation with treatments. We can only observe the weather
we cannot change it. The process of manipulation can alter how a system behaves
in ways that are not related to the treatment application, so we cannot really
study just the treatment effects. Epidemiological studies, like John Snow's 
investigation of the 1854 Cholera epidemic are by definition **observational**
studies: we observe what is happening, not conditions we create deliberately.

While one can assign conditions, ethical considerations might prevent us from 
doing so. How can we justify assigning harmful things and ask a person to
smoke two packs of cigarettes a day for the next 10 years? In the case of testing
a medical breakthrough against a horrible disease, how can we justify assigning
patients to a placebo group and withholding a potentially life-saving treatment?
To show that repeated head impact (RHI) causes chronic traumatic encephalopathy (CTE),
it would not be ethical to randomize subjects and hit those assigned to the RHI
arm of the study repeatedly over the head. 

When experimentation is not possible, we rely on **observational data**, analyzing
the data we can collect, and it is often the best we can do. How can we then explain 
the association we find in the data and get closer to establishing causality? 

To link RHI to CTE, we can study data on subjects who have been exposed to repeated 
head trauma, such as boxers and football players, and compare their likelihood of 
developing CTE to individuals who did not experience such head trauma. Comparisons
must be made with care. We would not want to compare star athletes who experience
head trauma with non-athletes who did not experience head trauma; there would
be too many confounding factors. Maybe we could follow a group of athletes
over time and record accumulated head impacts along with brain scans. While we 
cannot design an experiment, we can design how to collect observational data.

:::{.assignment}
::::{.assignment-header}
Assignment: Why Do Old Men Have Big Ears?
::::
::::{.assignment-container}
@Spiegelhalter2021 [p. 108--109] asks this question based on his personal 
experience that older men *seem* to have big ears. This question cannot be 
answered with a randomized controlled trial, we cannot assign ear lengths. 
It is what it is.

Observational studies in the UK and Japan collected cross-sectional data, that is, a sample 
from the current population, which will include men of different ages. Analyzing
the data the studies concluded that there is a positive correlation between 
age and ear length. For example, the figure below appeared in @Heathcote1995.
The study concluded that the regression trend was significant. The slope of the
regression line is 0.22mm per year with a 95\% confidence interval of [0.17, 0.27] 
mm per year. Because the confidence interval does not cover the value 0, the
trend is statistically significant. It seems that as we get older our ears get 
bigger by an average by 0.22 mm per year.

![Ear length. From @Heathcote1995.](images/EarLength.jpg){#fig-ear-length fig-align="center" width=50% .lightbox}

1. Try and explain the association between age and ear length in men. What are 
possible reasons ears are/appear larger in older men?

2. If you were to conduct a follow-up study to test the possible reasons in 1., 
what would the study look like? What kind of data would you collect? What
kind of men would you recruit for the study?

::::
:::

#### Quasi-experiments

If you cannot manipulate and control factors in an experiment, maybe you are lucky to
find data where the confounding factors have already been controlled for you.
Sometimes real life runs these quasi-experiments for us and eliminates the
confounding factors. Although the data is observational rather than experimental, 
it can go a long way toward establishing causality. In @sec-cholera-deeper
we discussed a second, deeper analysis John Snow conducted in which he compared 
cases between customers of the Lambeth and the Southward \& Vauxhall water companies.
For all intents and purposes the groups serviced by the two companies were identical
except for the source of the water. Lambeth's water was drawn upriver from sewage
discharge into the River Thames and was cleaner than the water from Southwark \&
Vauxhall, which drew water below the sewage discharge. The much higher cholera
incidence in the group supplied by Southwark \& Vauxhall was sufficient evidence
to implicate the water.

:::{.assignment}
::::{.assignment-header}
Assignment: Fluoride Exposure and IQ
::::
::::{.assignment-container}
The National Toxicology Program of the U.S. Department of Health and Human Services
conducted a **meta-analysis** of the relationship between fluoride intake and IQ.

Among the findings of the analysis, the article states (emphasis in original):

>*The NTP monograph concluded, with moderate confidence, that higher levels of 
fluoride exposure, such as drinking water containing more than 1.5 milligrams of 
fluoride per liter, are associated with lower IQ in children. The NTP review was 
designed to evaluate total fluoride exposure from all sources and was not designed 
to evaluate the health effects of fluoridated drinking water alone. 
**It is important to note that there were insufficient data to determine if the 
low fluoride level of 0.7 mg/L currently recommended for U.S. community water 
supplies has a negative effect on children’s IQ.** The NTP found no evidence that 
fluoride exposure had adverse effects on adult cognition.\
\
...\
\
The determination about lower IQs in children was based primarily on epidemiology 
studies in non-U.S. countries such as Canada, China, India, Iran, Pakistan, and Mexico 
where some pregnant women, infants, and children received total fluoride exposure 
amounts higher than 1.5 mg fluoride/L of drinking water. *

Please read the full article from the National Toxicology Program [here](https://ntp.niehs.nih.gov/whatwestudy/assessments/noncancer/completed/fluoride)
and answer the following questions:

1. Did the study establish correlation or causation between fluoride intake and children's IQ?
2. Does the article make it clear whether to take the results as an indication of causation
or correlation?
3. What is meta-analysis?
4. How do you interpret the fact that the study did not analyze data from the U.S.?
Does that affect whether the results are applicable to U.S. children?
5. Can you think of confounding factors that limit transfer of the results to the U.S?
6. Are you surprised that there is no evidence of adverse effects on adults?
::::
:::

In domains and applications where experimentation is not possible and confounding
factors are present, we try to establish causation by a process called 
[**causal inference**](https://en.wikipedia.org/wiki/Causal_inference). By studying which variables act on each other, causality can be inferred.

#### Hill's Criteria

Establishing causality from observational data, as in the case of Snow's 
water quality study, is a common problem in **epidemiology**, the study of the distribution
of diseases and health risks. Establishing designed experiments with randomized
control of factors is often not possible in those studies.

The English epidemiologist and statistician Sir Author Bradford Hill established 
nine principles that allow one to move from association to causation. These are known as
**Hill's criteria**, developed to establish causation involving
environmental exposure. Hill was part of the research team that confirmed the link 
between smoking and lung cancer. The criteria are:

1. **Strength**: strong association is stronger evidence of causality. A small
association does not rule out a causal effect, however.

2. **Consistency**: similar studies by others in different places with different
samples give consistent findings.

3. **Specificity**: the more specific the association between a factor and an
effect, the more likely we are dealing with cause and effect. The association
is specific when the cause leads to only one outcome and the outcome can only come from
the one cause.

4. **Temporarlity**: the effect comes after the cause. 

5. **Gradient**: an increase in level, intensity, duration or total level of
exposure to the potential cause leads to progressive increase in (the likelihood
of) the outcome.

6. **Plausibility**: the association is plausible based on known scientific facts.

7. **Coherence**: agreement between epidemiological and laboratory findings.
The interpretation of the data does not seriously conflict with what is already known
about the disease or exposure. 

8. **Experimentation**: if experimentation is possible, it provides results in 
support of the causal hypothesis (provides strong evidence).

9. **Analogy**: similarity between things that are otherwise different.
Scientists can use prior knowledge and patterns to infer similar causal associations.

Hill's criteria should be viewed as a [guideline]{.underline} for establishing causality
based on association. Proving causality is not done by clicking check boxes. Meeting
the criteria increases the likelihood that a factor causes an effect.

:::{.assignment}
::::{.assignment-header}
Assignment: Causal Link between RHI and CTE
::::
::::{.assignment-container}
Tiaina Baul "Junior" Seau was an outstanding linebacker who played in the National
Football League for 20 years, mostly with the San Diego Chargers and also the
Miami Dolphins and New England Patriots. He committed
suicide in 2012 by shooting himself in the chest. Junior did not leave a suicide
note but a piece of paper with lyrics from the country song "Who I Ain't". An 
autopsy confirmed that Junior Seau had suffered from chronic traumatic encephalopahty
(CTE) believed due to repeated head trauma he experienced as a football player.

![Junior Seau playing for the New England Patriots. Source: [Wikipedia](https://en.wikipedia.org/wiki/Junior_Seau)](images/Junior_Seau.jpeg){#fig-junior-seau fig-align="center" width=35%}

@Nowinski_et_al applied the Hill criteria to establish causality between 
repeated head impacts (RHI) and CTE. The authors discuss previous research on
the association of the two and resistance to calling the link between RHI and 
CTE causal. Interestingly, it appears that the causal link between the two was
settled throughout the 20th century when causality was called into question again.
The article is available [online](https://www.frontiersin.org/journals/neurology/articles/10.3389/fneur.2022.938163/full).

1. What reasons were given by some of the organizations involved in the debate 
(like CISG) to resist declaring a causal link between RHI and CTE?

2. What do you believe was their motivation to do so?

3. In the section *Understanding Causation*, the article examines each of 
Hill's nine criteria. Cite one argument from the article in support of each criterion.

4. Per the *Discussion* section of the article, what are valid reasons why 
scientists might remain skeptical of a causal link between RHI and CTE?

5. What language did the authors use in the *Conclusion* to indicate a causal
relationship between RHI and CTE?

6. Based on the evidence provided, should the conclusions drawn from data
about adult athletes be applied to children? Argue for or against and why or 
why not?

::::
:::

